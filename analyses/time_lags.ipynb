{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from joblib import Memory\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "import wildfires.analysis\n",
    "from wildfires.analysis import *\n",
    "from wildfires.dask_cx1 import get_client\n",
    "from wildfires.data import *\n",
    "from wildfires.logging_config import enable_logging\n",
    "\n",
    "FigureSaver.debug = True\n",
    "FigureSaver.directory = os.path.expanduser(os.path.join(\"~\", \"tmp\", \"time_lags\"))\n",
    "os.makedirs(FigureSaver.directory, exist_ok=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "enable_logging(\"jupyter\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Collapsing a non-contiguous coordinate.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*DEFAULT_SPHERICAL_EARTH_RADIUS*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*guessing contiguous bounds*\")\n",
    "\n",
    "normal_coast_linewidth = 0.5\n",
    "mpl.rc(\"figure\", figsize=(14, 6))\n",
    "mpl.rc(\"font\", size=9.0)\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "memory = get_memory(\"analysis_time_lags\", verbose=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Data Structures used for Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_months = [1, 3, 6, 12, 24]\n",
    "\n",
    "selection_variables = (\n",
    "    \"VOD Ku-band -3 Month\",\n",
    "    \"SIF\",\n",
    "    \"VOD Ku-band -1 Month\",\n",
    "    \"Dry Day Period -3 Month\",\n",
    "    \"FAPAR\",\n",
    "    \"pftHerb\",\n",
    "    \"LAI -1 Month\",\n",
    "    \"popd\",\n",
    "    \"Dry Day Period -24 Month\",\n",
    "    \"pftCrop\",\n",
    "    \"FAPAR -1 Month\",\n",
    "    \"FAPAR -24 Month\",\n",
    "    \"Max Temp\",\n",
    "    \"Dry Day Period -6 Month\",\n",
    "    \"VOD Ku-band -6 Month\",\n",
    ")\n",
    "\n",
    "ext_selection_variables = selection_variables + (\n",
    "    \"Dry Day Period -1 Month\",\n",
    "    \"FAPAR -6 Month\",\n",
    "    \"ShrubAll\",\n",
    "    \"SWI(1)\",\n",
    "    \"TreeAll\",\n",
    ")\n",
    "\n",
    "(\n",
    "    endog_data,\n",
    "    exog_data,\n",
    "    master_mask,\n",
    "    filled_datasets,\n",
    "    masked_datasets,\n",
    "    land_mask,\n",
    ") = wildfires.analysis.time_lags.get_data(selection_variables=selection_variables)\n",
    "\n",
    "(\n",
    "    s_endog_data,\n",
    "    s_exog_data,\n",
    "    s_master_mask,\n",
    "    s_filled_datasets,\n",
    "    s_masked_datasets,\n",
    "    s_land_mask,\n",
    ") = wildfires.analysis.time_lags.get_data(\n",
    "    shift_months=[1, 3, 6, 12, 24], selection_variables=selection_variables\n",
    ")\n",
    "\n",
    "(\n",
    "    e_s_endog_data,\n",
    "    e_s_exog_data,\n",
    "    e_s_master_mask,\n",
    "    e_s_filled_datasets,\n",
    "    e_s_masked_datasets,\n",
    "    e_s_land_mask,\n",
    ") = wildfires.analysis.time_lags.get_data(\n",
    "    shift_months=[1, 3, 6, 12, 24], selection_variables=ext_selection_variables\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimisation Using CX1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    exog_data, endog_data, random_state=1, shuffle=True, test_size=0.3\n",
    ")\n",
    "\n",
    "# Worker specifications.\n",
    "specs = {\"memory\": \"15GB\", \"walltime\": \"10:00:00\", \"cores\": 8}\n",
    "# Connect to an existing cluster with at least those specs.\n",
    "client = get_client(**specs)\n",
    "\n",
    "# Define the parameter space.\n",
    "parameters_RF = {\n",
    "    \"n_estimators\": [10, 50, 100],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [3, 10, 20],\n",
    "    \"max_features\": [\"auto\"],\n",
    "    \"bootstrap\": [False, True],\n",
    "    \"random_state\": [1],\n",
    "}\n",
    "\n",
    "\n",
    "def fit_func(X, y, rf_params):\n",
    "    rf = RandomForestRegressor(**rf_params)\n",
    "    scores = cross_val_score(rf, X, y, cv=5)\n",
    "    # XXX: What about the n_jobs parameters for the above two things?\n",
    "    # Optionally fit model on all the data and store the fitted model using pickle.\n",
    "    return scores\n",
    "\n",
    "\n",
    "# fitting = CX1Fit(X_train, y_train, data_name=\"full_no_shift\", param_grid=parameters_RF)\n",
    "# output = fitting.get_best_model(timeout=60 * 60)\n",
    "\n",
    "# scores_list = client.gather(client.map(fit_func, (X_train, y_train, dict(parameters_RF, params)\n",
    "#                                        for params in product(*list(\n",
    "# parameters_RF.values())))))\n",
    "print(\n",
    "    (X_train, y_train, dict(zip(parameters_RF, params)))\n",
    "    for params in product(*list(parameters_RF.values()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    regr = output[\"model\"]\n",
    "\n",
    "    print(estimator)\n",
    "    y_pred = regr.predict(X_test)\n",
    "\n",
    "    # Carry out predictions on the training dataset to diagnose overfitting.\n",
    "    y_pred_train = regr.predict(X_train)\n",
    "\n",
    "    results = {}\n",
    "    results[\"R2_train\"] = regr.score(X_train, y_train)\n",
    "    results[\"R2_test\"] = regr.score(X_test, y_test)\n",
    "\n",
    "    model_name = \"RF\"\n",
    "    print(f\"{model_name} R2 train: {results['R2_train']}\")\n",
    "    print(f\"{model_name} R2 test: {results['R2_test']}\")\n",
    "\n",
    "    importances = regr.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in regr.estimators_], axis=0)\n",
    "\n",
    "    importances_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Name\": exog_data.columns.values,\n",
    "            \"Importance\": importances,\n",
    "            \"Importance STD\": std,\n",
    "            \"Ratio\": np.array(std) / np.array(importances),\n",
    "        }\n",
    "    )\n",
    "    print(\n",
    "        \"\\n\"\n",
    "        + str(\n",
    "            importances_df.sort_values(\"Importance\", ascending=False).to_string(\n",
    "                index=False, float_format=\"{:0.3f}\".format, line_width=200\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
