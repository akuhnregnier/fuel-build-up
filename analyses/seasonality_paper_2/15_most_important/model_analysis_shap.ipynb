{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specific import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve previous results from the 'model' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_split_cache.load()\n",
    "rf = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0] / 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values - via PBS array jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal SHAP values - single thread timing\n",
    "\n",
    "~ ? s / sample, ? GB mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# get_shap_values(rf, X_train[0:100], interaction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([10, 30, 50, 100], [19.6, 57.2, 95, (3 * 60) + 18], marker=\"o\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"time (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values - see PBS (array) job folder 'shap'!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the SHAP values (keeping track of missing chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 655  # Maximum job array index (inclusive).\n",
    "job_samples = 2000  # Samples per job.\n",
    "total_samples = (max_index + 1) * job_samples  # Sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the individual data chunks.\n",
    "shap_chunks = []\n",
    "missing = []\n",
    "for index in tqdm(range(max_index + 1), desc=\"Loading chunks\"):\n",
    "    try:\n",
    "        shap_chunks.append(\n",
    "            SimpleCache(\n",
    "                f\"tree_path_dependent_shap_{index}_{job_samples}\",\n",
    "                cache_dir=os.path.join(CACHE_DIR, \"shap\"),\n",
    "                verbose=0,\n",
    "            ).load()\n",
    "        )\n",
    "    except NoCachedDataError:\n",
    "        missing.append(index)\n",
    "\n",
    "if missing:\n",
    "    print(\"missing:\", missing)\n",
    "    print(\"nr missing:\", len(missing))\n",
    "\n",
    "shap_values = np.vstack(shap_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual recalculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "\n",
    "# def cached_get_shap_values(index, model, X):\n",
    "#     tree_path_dependent_shap_cache = SimpleCache(\n",
    "#         f\"tree_path_dependent_shap_{index}_{job_samples}\",\n",
    "#         cache_dir=os.path.join(CACHE_DIR, \"shap\"),\n",
    "#     )\n",
    "#     @tree_path_dependent_shap_cache\n",
    "#     def _shap_vals():\n",
    "#         return get_shap_values(model, X, interaction=False)\n",
    "#     return _shap_vals()\n",
    "\n",
    "# with multiprocessing.Pool(processes=get_ncpus()) as pool:\n",
    "#     async_results = [\n",
    "#         pool.apply_async(\n",
    "#             cached_get_shap_values, (\n",
    "#                 index,\n",
    "#                 rf,\n",
    "#                 X_train[index * job_samples : (index + 1) * job_samples]\n",
    "#             )\n",
    "#         )\n",
    "#         for index in [2, 11, 12, 13, 121, 122, 123, 124, 125, 126, 127, 226, 227, 229, 231]\n",
    "#     ]\n",
    "#     results = [async_result.get() for async_result in async_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with figure_saver(\"SHAP\"):\n",
    "    shap.summary_plot(\n",
    "        shap_values,\n",
    "        shorten_columns(X_train[:total_samples]),\n",
    "        title=\"SHAP Feature Importances\",\n",
    "        show=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "mean_shap_importances = pd.DataFrame(\n",
    "    [shorten_features(X_train.columns), mean_abs_shap], index=[\"column\", \"shap\"]\n",
    ")\n",
    "mean_shap_importances = mean_shap_importances.T\n",
    "mean_shap_importances.sort_values(\"shap\", ascending=False, inplace=True)\n",
    "mean_shap_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction SHAP values - see PBS (array) job folder 'shap_interaction'!\n",
    "\n",
    "~ ? s / sample !!, ? GB mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# get_shap_values(rf, X_train[0:5], interaction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 5999  # Maximum job array index (inclusive).\n",
    "job_samples = 50  # Samples per job.\n",
    "total_interact_samples = (max_index + 1) * job_samples\n",
    "\n",
    "shap_interact_cache = SimpleCache(\n",
    "    \"shap_interact_cache\", cache_dir=CACHE_DIR / Path(\"shap_interaction\")\n",
    ")\n",
    "\n",
    "\n",
    "@shap_interact_cache\n",
    "def load_shap_interact_from_chunks():\n",
    "    # Load the individual data chunks.\n",
    "    shap_interact_chunks = []\n",
    "    missing = []\n",
    "    for index in tqdm(range(0, max_index + 1), desc=\"Loading chunks\"):\n",
    "        try:\n",
    "            shap_interact_chunks.append(\n",
    "                SimpleCache(\n",
    "                    f\"tree_path_dependent_shap_interact_{index}_{job_samples}\",\n",
    "                    cache_dir=os.path.join(CACHE_DIR, \"shap_interaction\"),\n",
    "                    verbose=0,\n",
    "                ).load()\n",
    "            )\n",
    "        except NoCachedDataError:\n",
    "            missing.append(index)\n",
    "\n",
    "    if missing:\n",
    "        print(\"missing:\", missing)\n",
    "        print(\"nr missing:\", len(missing))\n",
    "        raise Exception(\"missing data\")\n",
    "\n",
    "    return np.vstack(shap_interact_chunks)\n",
    "\n",
    "\n",
    "shap_interact_values = load_shap_interact_from_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with figure_saver(\"SHAP_interaction\"):\n",
    "    shap.summary_plot(\n",
    "        shap_interact_values,\n",
    "        shorten_columns(X_train[:total_interact_samples]),\n",
    "        title=\"SHAP Feature Interactions\",\n",
    "        show=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with figure_saver(\"SHAP_interaction_compact\"):\n",
    "    shap.summary_plot(\n",
    "        shap_interact_values,\n",
    "        shorten_columns(X_train[:total_interact_samples]),\n",
    "        title=\"SHAP Feature Interactions\",\n",
    "        show=False,\n",
    "        plot_type=\"compact_dot\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_interact = np.mean(np.abs(shap_interact_values), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.heatmap(\n",
    "    np.log(mean_interact),\n",
    "    square=True,\n",
    "    xticklabels=shorten_features(X_train.columns),\n",
    "    yticklabels=shorten_features(X_train.columns),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.xaxis.set_tick_params(rotation=90)\n",
    "ax.yaxis.set_tick_params(rotation=0)\n",
    "_ = fig.suptitle(\"log(SHAP Interaction Values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the most significant interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_interact_index(index, mean_interact):\n",
    "    indices = np.argsort(-mean_interact[index])\n",
    "    return indices[indices != index][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_mean_interact = mean_interact.copy()\n",
    "masked_mean_interact[np.triu_indices(mean_interact.shape[0])] = np.nan\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.heatmap(\n",
    "    np.log(masked_mean_interact),\n",
    "    square=True,\n",
    "    xticklabels=shorten_features(X_train.columns),\n",
    "    yticklabels=shorten_features(X_train.columns),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.xaxis.set_tick_params(rotation=90)\n",
    "ax.yaxis.set_tick_params(rotation=0)\n",
    "_ = fig.suptitle(\"log(SHAP Interaction Values)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_indices = np.tril_indices(mean_interact.shape[0])\n",
    "interact_values = mean_interact[interact_indices]\n",
    "\n",
    "interact_data = {}\n",
    "for i, j, interact_value in zip(*interact_indices, interact_values):\n",
    "    if i == j:\n",
    "        continue\n",
    "    interact_data[\n",
    "        tuple(\n",
    "            sorted(\n",
    "                (\n",
    "                    shorten_features(X_train.columns[i]),\n",
    "                    shorten_features(X_train.columns[j]),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ] = interact_value\n",
    "\n",
    "interact_data = pd.Series(interact_data).sort_values(ascending=False, inplace=False)\n",
    "\n",
    "interact_data_cache = SimpleCache(\"SHAP_interact_data\", cache_dir=CACHE_DIR)\n",
    "\n",
    "\n",
    "@interact_data_cache\n",
    "def dummy_func():\n",
    "    return interact_data\n",
    "\n",
    "\n",
    "dummy_func()\n",
    "\n",
    "print(interact_data[:40].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_data[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the approximate and 'exact' interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 18\n",
    "header = f\"{'Feature':>{length}} : {'Approx':>{length}} {'Non Approx':>{length}}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for i in range(len(X_train.columns)):\n",
    "    approx = shap.common.approximate_interactions(\n",
    "        X_train.columns[i], shap_values, X_train[:total_samples]\n",
    "    )[0]\n",
    "    non_approx = get_highest_interact_index(i, mean_interact)\n",
    "    features = shorten_features(\n",
    "        X_train.columns[index] for index in (i, approx, non_approx)\n",
    "    )\n",
    "    print(f\"{features[0]:>{length}} : {features[1]:>{length}} {features[2]:>{length}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependence plots with the approximate dependence metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_dependence_plot(i, shap_values=shap_values, X=X_train[:total_samples]):\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    shap.dependence_plot(\n",
    "        i, shap_values, X, alpha=0.1, ax=ax,\n",
    "    )\n",
    "    figure_saver.save_figure(\n",
    "        fig,\n",
    "        f\"shap_dependence_{X_train.columns[i]}_approx\",\n",
    "        sub_directory=\"shap_dependence_approx\",\n",
    "    )\n",
    "\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=32) as executor:\n",
    "    plot_fs = []\n",
    "    for i in range(len(X_train.columns)):\n",
    "        plot_fs.append(executor.submit(approx_dependence_plot, i))\n",
    "\n",
    "    for plot_f in tqdm(\n",
    "        concurrent.futures.as_completed(plot_fs),\n",
    "        total=len(plot_fs),\n",
    "        desc=\"Plotting approx SHAP dependence plots\",\n",
    "    ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependence_plot(\n",
    "    i, shap_values=shap_values, X=X_train[:total_samples], mean_interact=mean_interact\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    shap.dependence_plot(\n",
    "        i,\n",
    "        shap_values,\n",
    "        X,\n",
    "        interaction_index=get_highest_interact_index(i, mean_interact),\n",
    "        alpha=0.1,\n",
    "        ax=ax,\n",
    "    )\n",
    "    figure_saver.save_figure(\n",
    "        fig, f\"shap_dependence_{X_train.columns[i]}\", sub_directory=\"shap_dependence\"\n",
    "    )\n",
    "\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=32) as executor:\n",
    "    plot_fs = []\n",
    "    for i in range(len(X_train.columns)):\n",
    "        plot_fs.append(executor.submit(dependence_plot, i))\n",
    "\n",
    "    for plot_f in tqdm(\n",
    "        concurrent.futures.as_completed(plot_fs),\n",
    "        total=len(plot_fs),\n",
    "        desc=\"Plotting SHAP dependence plots\",\n",
    "    ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP force plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### force_plot memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5e4 * (5e4 - 1) // 2) * 8 / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.n_jobs = 32\n",
    "N = int(1e3)\n",
    "shap.force_plot(\n",
    "    np.mean(rf.predict(X_train[:N])), shap_values[:N], shorten_columns(X_train[:N])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
