{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specific import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve previous results from the 'model' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_split_cache.load()\n",
    "results, rf = cross_val_cache.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(n_workers=1, threads_per_worker=8, resources={'threads': 8})\n",
    "client = get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fut = client.scatter(rf, broadcast=True)\n",
    "X_fut = client.scatter(X_train, broadcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = list(combinations(X_train.columns, 2))\n",
    "print(\"Total nr. of columns:\", len(columns_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D ALE Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: Local trial\n",
    "# save_ale_2d_and_get_importance(rf, X_train[:20000], X_train.columns[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Parallelisation capacity - around 8 cores per worker looks good\n",
    "\n",
    "Note that it is impractical to spawn 32 workers with 1 process each since they will all have their own memory copies. \n",
    "Only around 60GB of memory is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "n_jobs_list = [1, 4, 7, 10, 12, 15, 18, 22, 26, 30][::-1]\n",
    "\n",
    "for n_jobs in tqdm(n_jobs_list):\n",
    "    start = time()\n",
    "    ale_f = client.submit(\n",
    "        add_common_path_deco(save_ale_2d_and_get_importance),\n",
    "        model=rf_fut,\n",
    "        train_set=X_fut,\n",
    "        features=columns_list[0],\n",
    "        n_jobs=n_jobs,\n",
    "        resources={\"threads\": 1},\n",
    "        pure=False,\n",
    "    )\n",
    "    dask.distributed.wait(ale_f)\n",
    "\n",
    "    if ale_f.status == \"error\":\n",
    "        print(ale_f.result())\n",
    "        times.append(0)\n",
    "    else:\n",
    "        times.append(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time for 1 cpu core:\", times[-1])\n",
    "print(\"nr of tasks:\", len(columns_list))\n",
    "\n",
    "n_workers = 320\n",
    "total_time = len(columns_list) * times[-1]\n",
    "print(f\"Time with {n_workers} workers: {(total_time / n_workers) / (60 * 60)} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.array(times)\n",
    "n_jobs_list = np.array(n_jobs_list)\n",
    "plt.plot(n_jobs_list, (1 / times) / n_jobs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local 2D ALE plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top interactions first.\n",
    "interact_data_cache = SimpleCache(\"SHAP_interact_data\", cache_dir=CACHE_DIR)\n",
    "interact_data = interact_data_cache.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_data[:10].index.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[shorten_features(cs) for cs in columns_list if \"Max Temp\" in cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    set(shorten_features(cs)) == set([\"Max Temp\", \"VOD 3 M\"])\n",
    "    for cs in columns_list\n",
    "    if \"Max Temp\" in cs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for columns in columns_list:\n",
    "# for columns in [('Max Temp', 'lightning')]:\n",
    "for interact_columns in tqdm(interact_data.index.to_list(), desc=\"2D ALE plots\"):\n",
    "    matching_cols = [\n",
    "        cs for cs in columns_list if set(shorten_features(cs)) == set(interact_columns)\n",
    "    ]\n",
    "    assert len(matching_cols) == 1, matching_cols\n",
    "    columns = matching_cols[0]\n",
    "\n",
    "    save_ale_2d_and_get_importance(\n",
    "        model=rf,\n",
    "        train_set=X_train,\n",
    "        features=columns,\n",
    "        n_jobs=get_ncpus(),\n",
    "        include_first_order=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 2D ALE plotting in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_ale_2d_cache = SimpleCache(\"world_ale_2d\", cache_dir=CACHE_DIR)\n",
    "\n",
    "n_threads = common_worker_threads(client)  # The number of threads per worker.\n",
    "\n",
    "# XXX:\n",
    "n_threads //= 2\n",
    "\n",
    "\n",
    "@world_ale_2d_cache\n",
    "def get_world_ale_2d():\n",
    "    ale_fs = [\n",
    "        client.submit(\n",
    "            add_common_path_deco(save_ale_2d_and_get_importance),\n",
    "            model=rf_fut,\n",
    "            train_set=X_fut,\n",
    "            features=columns,\n",
    "            n_jobs=n_threads,\n",
    "            resources={\"threads\": n_threads},\n",
    "        )\n",
    "        for columns in columns_list\n",
    "    ]\n",
    "\n",
    "    for ale_f in tqdm(\n",
    "        dask.distributed.as_completed(ale_fs),\n",
    "        total=len(ale_fs),\n",
    "        unit=\"plot\",\n",
    "        desc=\"Calculating 2D ALE plots\",\n",
    "        smoothing=0,\n",
    "    ):\n",
    "        if ale_f.status == \"error\":\n",
    "            print(ale_f.result())\n",
    "\n",
    "    ptp_values = {}\n",
    "\n",
    "    for columns, ale_f in zip(columns_list, ale_fs):\n",
    "        ptp_values[columns] = ale_f.result()\n",
    "    return ptp_values\n",
    "\n",
    "\n",
    "ptp_values = get_world_ale_2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat with first order effects just for the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_threads = common_worker_threads(client)  # The number of threads per worker.\n",
    "\n",
    "# XXX:\n",
    "n_threads //= 2\n",
    "\n",
    "ale_fs = []\n",
    "for columns in columns_list:\n",
    "    if not os.path.isfile(\n",
    "        os.path.join(\n",
    "            figure_saver.directories[0],\n",
    "            \"2d_ale_first_order\",\n",
    "            \"__\".join(columns) + \".png\",\n",
    "        )\n",
    "    ):\n",
    "        ale_fs.append(\n",
    "            client.submit(\n",
    "                add_common_path_deco(save_ale_2d_and_get_importance),\n",
    "                model=rf_fut,\n",
    "                train_set=X_fut,\n",
    "                features=columns,\n",
    "                n_jobs=n_threads,\n",
    "                resources={\"threads\": n_threads},\n",
    "                include_first_order=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "for ale_f in tqdm(\n",
    "    dask.distributed.as_completed(ale_fs),\n",
    "    total=len(ale_fs),\n",
    "    unit=\"plot\",\n",
    "    desc=\"Calculating 2D ALE plots\",\n",
    "    smoothing=0,\n",
    "):\n",
    "    if ale_f.status == \"error\":\n",
    "        print(ale_f.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore and count None values, then plot a histogram of the ptp values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_columns_list = []\n",
    "filtered_ptp_values = []\n",
    "for columns, ptp in ptp_values.items():\n",
    "    if ptp is not None:\n",
    "        filtered_columns_list.append(columns)\n",
    "        filtered_ptp_values.append(ptp)\n",
    "    else:\n",
    "        print(\"Error for columns:\", columns)\n",
    "\n",
    "np.asarray([ptp for ptp in ptp_values if ptp is not None])\n",
    "_ = plt.hist(filtered_ptp_values, bins=20)\n",
    "\n",
    "pdp_results = pd.Series(filtered_ptp_values, index=filtered_columns_list)\n",
    "pdp_results.sort_values(inplace=True, ascending=False)\n",
    "print(pdp_results.head(20))\n",
    "plt.figure()\n",
    "plt.plot(pdp_results.values, marker=\"o\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"2D Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDP Plotting - see array job folder 'pdp_2d'\n",
    "\n",
    "Not everything may have been computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_pdp_plot_2d(rf, X_train[:1000], columns_list[0], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_pdp_plot_2d(rf, X_train[:10000], columns_list[0], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_pdp_plot_2d(rf, X_train[:100000], columns_list[0], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not really practical since it takes too long - use array jobs instead!\n",
    "\n",
    "%%time\n",
    "n_threads = 8\n",
    "pdp_fs = [\n",
    "    client.submit(\n",
    "        add_common_path_deco(save_pdp_plot_2d),\n",
    "        model=rf_fut,\n",
    "        X_train=X_fut,\n",
    "        features=columns,\n",
    "        n_jobs=n_threads,\n",
    "        resources={\"threads\": n_threads},\n",
    "    )\n",
    "    for columns in columns_list\n",
    "]\n",
    "\n",
    "for pdp_f in tqdm(\n",
    "    dask.distributed.as_completed(pdp_fs),\n",
    "    total=len(pdp_fs),\n",
    "    unit=\"plot\",\n",
    "    desc=\"Calculating 2D PDP plots\",\n",
    "    smoothing=0,\n",
    "):\n",
    "    if pdp_f.status == \"error\":\n",
    "        print(pdp_f.result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires]",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
