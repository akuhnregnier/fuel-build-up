{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specific import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    endog_data,\n",
    "    exog_data,\n",
    "    master_mask,\n",
    "    filled_datasets,\n",
    "    masked_datasets,\n",
    "    land_mask,\n",
    ") = get_offset_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve previous results from the 'model' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_split_cache.load()\n",
    "results, rf = cross_val_cache.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values - see PBS (array) job folder 'shap'!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the SHAP values (keeping track of missing chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 995  # Maximum job array index (inclusive).\n",
    "job_samples = 2000  # Samples per job.\n",
    "total_samples = (max_index + 1) * job_samples  # Sanity check.\n",
    "\n",
    "# Load the individual data chunks.\n",
    "shap_chunks = []\n",
    "missing = []\n",
    "for index in tqdm(range(max_index + 1), desc=\"Loading chunks\"):\n",
    "    try:\n",
    "        shap_chunks.append(\n",
    "            SimpleCache(\n",
    "                f\"tree_path_dependent_shap_{index}_{job_samples}\",\n",
    "                cache_dir=os.path.join(CACHE_DIR, \"shap\"),\n",
    "                verbose=0,\n",
    "            ).load()\n",
    "        )\n",
    "    except NoCachedDataError:\n",
    "        missing.append(index)\n",
    "\n",
    "if missing:\n",
    "    print(\"missing:\", missing)\n",
    "    print(\"nr missing:\", len(missing))\n",
    "\n",
    "shap_values = np.vstack(shap_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BA in the train and test sets\n",
    "\n",
    "Valid elements are situated where master_mask is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indices = np.where(~master_mask.ravel())[0]\n",
    "\n",
    "valid_train_indices, valid_test_indices = train_test_split(\n",
    "    valid_indices, random_state=1, shuffle=True, test_size=0.3\n",
    ")\n",
    "\n",
    "masked_train_data = np.ma.MaskedArray(\n",
    "    np.zeros_like(master_mask, dtype=np.float64), mask=np.ones_like(master_mask)\n",
    ")\n",
    "masked_train_data.ravel()[valid_train_indices] = y_train.values\n",
    "\n",
    "masked_test_data = np.ma.MaskedArray(\n",
    "    np.zeros_like(master_mask, dtype=np.float64), mask=np.ones_like(master_mask)\n",
    ")\n",
    "masked_test_data.ravel()[valid_test_indices] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with figure_saver(\"train_test_set_overall_ba_comp\"):\n",
    "    fig, axes = plt.subplots(\n",
    "        3,\n",
    "        1,\n",
    "        constrained_layout=True,\n",
    "        figsize=(5.1, 8.4),\n",
    "        subplot_kw={\"projection\": ccrs.Robinson()},\n",
    "    )\n",
    "    shared_kwargs = {\n",
    "        \"boundaries\": [0, 4e-6, 1e-5, 1e-4, 1e-3, 1e-2, 8e-2],\n",
    "        \"extend\": \"max\",\n",
    "        \"cmap\": \"inferno\",\n",
    "        \"colorbar_kwargs\": {\"format\": \"%0.1e\", \"label\": \"Fractional BA\"},\n",
    "        \"coastline_kwargs\": {\"linewidth\": 0.3},\n",
    "        \"title\": \"\",\n",
    "    }\n",
    "    axes[0].set_title(\"Mean Overall GFED4 BA\")\n",
    "    cube_plotting(\n",
    "        get_masked_array(endog_data.values, master_mask),\n",
    "        ax=axes[0],\n",
    "        fig=fig,\n",
    "        **shared_kwargs\n",
    "    )\n",
    "    axes[1].set_title(\"Mean Train Set GFED4 BA\")\n",
    "    cube_plotting(masked_train_data, ax=axes[1], fig=fig, **shared_kwargs)\n",
    "    axes[2].set_title(\"Mean Test Set GFED4 BA\")\n",
    "    cube_plotting(masked_test_data, ax=axes[2], fig=fig, **shared_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.abs(shap_values[:, 0]), bins=5000)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_shap_arrs = []\n",
    "vmins = []\n",
    "vmaxs = []\n",
    "\n",
    "for i, feature in enumerate(tqdm(X_train.columns, desc=\"Computing SHAP values\")):\n",
    "    masked_shap_comp = np.ma.MaskedArray(\n",
    "        np.zeros_like(master_mask, dtype=np.float64), mask=np.ones_like(master_mask)\n",
    "    )\n",
    "    masked_shap_comp.ravel()[valid_train_indices[: shap_values.shape[0]]] = shap_values[\n",
    "        :, i\n",
    "    ]\n",
    "    avg_shap_comp = np.ma.mean(masked_shap_comp, axis=0)\n",
    "    masked_shap_arrs.append(avg_shap_comp)\n",
    "    vmins.append(np.min(avg_shap_comp))\n",
    "    vmaxs.append(np.max(avg_shap_comp))\n",
    "\n",
    "vmin = min(vmins)\n",
    "vmax = max(vmaxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(tqdm(X_train.columns, desc=\"Mapping SHAP values\")):\n",
    "    fig = cube_plotting(\n",
    "        masked_shap_arrs[i],\n",
    "        fig=plt.figure(figsize=(5.1, 2.8)),\n",
    "        title=f\"Mean SHAP value for '{shorten_features(feature)}'\",\n",
    "        cmap=\"Spectral_r\",\n",
    "        nbins=7,\n",
    "        cmap_midpoint=0,\n",
    "        cmap_symmetric=True,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        log=True,\n",
    "        log_auto_bins=False,\n",
    "        min_edge=1e-3,\n",
    "        extend=\"neither\",\n",
    "        colorbar_kwargs={\n",
    "            \"format\": \"%0.1e\",\n",
    "            \"label\": f\"SHAP ('{shorten_features(feature)}')\",\n",
    "        },\n",
    "        coastline_kwargs={\"linewidth\": 0.3},\n",
    "    )\n",
    "    figure_saver.save_figure(fig, f\"shap_value_map_{feature}\", sub_directory=\"shap_map\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires]",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
