{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that the two datasets measure inherently different things!\n",
    "\n",
    "WWLLN measure ground strikes explicitly, while CAPE x Precip is a proxy for (cloud) lighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "from collections import namedtuple\n",
    "from functools import reduce\n",
    "from itertools import combinations\n",
    "from operator import mul\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from loguru import logger as loguru_logger\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wildfires.analysis\n",
    "from alepython import ale_plot\n",
    "from alepython.ale import _second_order_ale_quant\n",
    "from wildfires.analysis import *\n",
    "from wildfires.dask_cx1 import get_client\n",
    "from wildfires.data import *\n",
    "from wildfires.logging_config import enable_logging\n",
    "from wildfires.qstat import get_ncpus\n",
    "from wildfires.utils import *\n",
    "\n",
    "loguru_logger.enable(\"alepython\")\n",
    "loguru_logger.remove()\n",
    "loguru_logger.add(sys.stderr, level=\"WARNING\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "enable_logging(\"jupyter\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Collapsing a non-contiguous coordinate.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*DEFAULT_SPHERICAL_EARTH_RADIUS*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*guessing contiguous bounds*\")\n",
    "\n",
    "normal_coast_linewidth = 0.5\n",
    "mpl.rc(\"figure\", figsize=(14, 6))\n",
    "mpl.rc(\"font\", size=9.0)\n",
    "\n",
    "figure_saver = FigureSaver(\n",
    "    directories=os.path.join(\"~\", \"tmp\", \"analysis_wwlln_vs_cape_precip\"), debug=True\n",
    ")\n",
    "memory = get_memory(\"analysis_wwlln_vs_cape_precip\", verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load WWLLN and CAPExPRECIP Data\n",
    "### Compare at their native resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwlln = WWLLN()\n",
    "cape_precip = ERA5_CAPEPrecip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = Datasets([wwlln, cape_precip])\n",
    "dataset_times(datasets, lat_lon=True)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cube_plotting(wwlln.cube, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cube_plotting(cape_precip.cube, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale to the same grid and compute correlations overall and over land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly, mean, climatology = prepare_selection(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regridded Mean Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_times(monthly, lat_lon=True)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cube in mean.cubes:\n",
    "    cube_plotting(cube, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard deviation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cube in monthly.cubes:\n",
    "    cube_plotting(\n",
    "        cube.collapsed(\"time\", iris.analysis.STD_DEV),\n",
    "        log=True,\n",
    "        title=f\"STD: {cube.name()}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "for selection in (monthly, climatology):\n",
    "    selection.homogenise_masks()\n",
    "    overall_mask = reduce(np.logical_or, [cube.data.mask for cube in selection.cubes])\n",
    "    selection.apply_masks(overall_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.corrcoef(*[get_unmasked(cube.data) for cube in monthly.cubes])\n",
    "assert corr_mat.shape[0] == 2, \"Expect only 2 variables.\"\n",
    "print(\"Monthly, all, corr:\", corr_mat[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = ~get_land_mask()\n",
    "monthly_land = monthly.copy(deep=True)\n",
    "monthly_land.apply_masks(land_mask)\n",
    "corr_mat = np.corrcoef(*[get_unmasked(cube.data) for cube in monthly_land.cubes])\n",
    "assert corr_mat.shape[0] == 2, \"Expect only 2 variables.\"\n",
    "print(\"Monthly, land, corr:\", corr_mat[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "arrs = [get_unmasked(cube.data) for cube in monthly_land.cubes]\n",
    "names = list(monthly_land.pretty_variable_names)\n",
    "plt.hexbin(*arrs, bins=\"log\")\n",
    "plt.xlabel(names[0])\n",
    "_ = plt.ylabel(names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climatological correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.corrcoef(*[get_unmasked(cube.data) for cube in climatology.cubes])\n",
    "assert corr_mat.shape[0] == 2, \"Expect only 2 variables.\"\n",
    "print(\"Monthly, all, corr:\", corr_mat[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = ~get_land_mask()\n",
    "climatology_land = climatology.copy(deep=True)\n",
    "climatology_land.apply_masks(land_mask)\n",
    "corr_mat = np.corrcoef(*[get_unmasked(cube.data) for cube in climatology_land.cubes])\n",
    "assert corr_mat.shape[0] == 2, \"Expect only 2 variables.\"\n",
    "print(\"Monthly, land, corr:\", corr_mat[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "arrs = [get_unmasked(cube.data) for cube in climatology_land.cubes]\n",
    "names = list(climatology_land.pretty_variable_names)\n",
    "plt.hexbin(*arrs, bins=\"log\")\n",
    "plt.xlabel(names[0])\n",
    "_ = plt.ylabel(names[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
