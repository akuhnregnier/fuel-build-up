#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
from pathlib import Path

from wildfires.utils import handle_array_job_args

try:
    # This will only work after the path modification carried out in the job script.
    from specific import (
        CACHE_DIR,
        SimpleCache,
        get_model,
        data_split_cache,
        get_shap_values,
    )
except ImportError:
    """Not running as an HPC job yet."""


# About 2 s / sample
# Expect ~ 1 hr per job -> 2000 samples in 2 hrs each (allowing for poor performance)


def func():
    # Used to re-compute specific failed jobs, `None` otherwise.
    indices = [
        3,
        4,
        6,
        7,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        58,
        59,
        60,
        61,
        62,
        63,
        65,
        66,
        69,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        87,
        88,
        112,
        113,
        114,
        115,
        116,
        117,
        121,
        122,
        123,
        124,
        125,
        127,
        128,
        129,
        130,
        131,
        133,
        134,
        136,
        137,
        142,
        143,
        144,
        147,
        150,
        151,
        153,
        154,
        179,
        180,
        182,
        183,
        185,
        186,
        187,
        188,
        196,
        197,
        198,
        199,
        200,
        201,
        205,
        209,
        210,
        211,
        222,
        223,
        241,
        242,
        243,
        244,
        245,
        246,
        247,
        248,
        249,
        250,
        251,
        252,
        253,
        256,
        257,
        258,
        259,
        260,
        261,
        262,
        263,
        264,
        270,
        272,
        273,
        274,
        278,
        279,
        280,
        283,
        284,
        303,
        304,
        305,
        306,
        307,
        308,
        309,
        310,
        313,
        314,
        316,
        325,
        326,
        327,
        328,
        329,
        330,
        334,
        337,
        338,
        339,
        351,
        352,
        361,
        362,
        363,
        364,
        365,
        366,
        367,
        368,
        369,
        370,
        371,
        372,
        374,
        375,
        376,
        377,
        378,
        379,
        380,
        382,
        383,
        389,
        390,
        391,
        394,
        398,
        400,
        401,
        402,
        403,
        422,
        423,
        425,
        426,
        429,
        431,
        432,
        433,
        442,
        443,
        444,
        445,
        446,
        447,
        450,
        454,
        455,
        456,
        464,
        465,
        479,
        480,
        481,
        482,
        483,
        484,
        485,
        486,
        487,
        488,
        489,
        490,
        493,
        494,
        495,
        496,
        497,
        498,
        499,
        501,
        502,
        515,
        521,
        522,
        523,
        529,
        530,
        531,
        534,
        535,
        539,
        540,
        552,
        553,
        554,
        555,
        557,
        558,
        559,
        560,
        564,
        565,
        566,
        568,
        569,
        570,
        573,
        575,
        576,
        577,
        578,
        591,
        593,
        594,
        595,
        596,
        597,
        598,
        599,
        600,
        601,
        602,
        603,
        605,
        606,
        607,
        608,
        609,
    ]

    index = int(os.environ["PBS_ARRAY_INDEX"])

    if indices is not None:
        index = indices[index]

    print("Index:", index)

    X_train, X_test, y_train, y_test = data_split_cache.load()
    rf = get_model()

    job_samples = 2000

    tree_path_dependent_shap_cache = SimpleCache(
        f"tree_path_dependent_shap_{index}_{job_samples}",
        cache_dir=os.path.join(CACHE_DIR, "shap"),
    )

    @tree_path_dependent_shap_cache
    def cached_get_shap_values(model, X):
        return get_shap_values(model, X, interaction=False)

    cached_get_shap_values(rf, X_train[index * job_samples : (index + 1) * job_samples])


if __name__ == "__main__":
    handle_array_job_args(
        Path(__file__).resolve(),
        func,
        ncpus=1,
        mem="7gb",
        walltime="05:00:00",
        max_index=250,
    )
