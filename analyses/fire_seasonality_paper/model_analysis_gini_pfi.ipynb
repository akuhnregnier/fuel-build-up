{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve previous results from the 'model' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_split_cache.load()\n",
    "results, rf = cross_val_cache.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELI5 Permutation Importances (PFI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "from wildfires.dask_cx1 import get_parallel_backend\n",
    "\n",
    "perm_importance_cache = SimpleCache(\n",
    "    \"perm_importance\", cache_dir=CACHE_DIR, pickler=cloudpickle\n",
    ")\n",
    "\n",
    "# Does not seem to work with the dask parallel backend - it gets bypassed\n",
    "# and every available core on the machine is used up if attempted.\n",
    "\n",
    "\n",
    "@perm_importance_cache\n",
    "def get_perm_importance():\n",
    "    rf.n_jobs = 30\n",
    "    return eli5.sklearn.PermutationImportance(rf).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# worker = list(client.scheduler_info()['workers'])[0]\n",
    "# perm_importance = client.run(get_perm_importance, workers=[worker])\n",
    "\n",
    "perm_importance = get_perm_importance()\n",
    "perm_df = eli5.explain_weights_df(perm_importance, feature_names=list(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VIF Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vif_cache = SimpleCache(\"train_vif\", cache_dir=CACHE_DIR)\n",
    "\n",
    "\n",
    "@train_vif_cache\n",
    "def get_vifs():\n",
    "    return vif(X_train, verbose=True)\n",
    "\n",
    "\n",
    "vifs = get_vifs()\n",
    "vifs = vifs.set_index(\"Name\", drop=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Tree Importances - Gini vs PFI vs SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_col = 20\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, sharex=True, figsize=(7, 12))\n",
    "\n",
    "# Unpack\n",
    "ax, ax2, ax3, ax4 = axes\n",
    "\n",
    "# Gini values.\n",
    "ind_trees_gini = pd.DataFrame(\n",
    "    [tree.feature_importances_ for tree in rf], columns=X_train.columns,\n",
    ")\n",
    "mean_importances = ind_trees_gini.mean().sort_values(ascending=False)\n",
    "ind_trees_gini = ind_trees_gini.reindex(mean_importances.index, axis=1)\n",
    "sns.boxplot(data=ind_trees_gini.iloc[:, :N_col], ax=ax)\n",
    "ax.set(\n",
    "    # title=\"Gini Importances\",\n",
    "    ylabel=\"Gini Importance (MSE)\\n\"\n",
    ")\n",
    "\n",
    "# PFI values.\n",
    "pfi_ind = pd.DataFrame(perm_importance.results_, columns=X_train.columns)\n",
    "\n",
    "# Re-index according to the same ordering as for the Gini importances!\n",
    "pfi_ind = pfi_ind.reindex(mean_importances.index, axis=1)\n",
    "\n",
    "sns.boxplot(data=pfi_ind.iloc[:, :N_col], ax=ax2)\n",
    "ax2.set(\n",
    "    # title=\"PFI Importances\",\n",
    "    ylabel=\"PFI Importance\\n\"\n",
    ")\n",
    "\n",
    "# SHAP values.\n",
    "total_samples = 20000\n",
    "tree_path_dependent_shap_cache = SimpleCache(\n",
    "    f\"tree_path_dependent_shap_{total_samples}\", cache_dir=CACHE_DIR\n",
    ")\n",
    "shap_values = tree_path_dependent_shap_cache.load()\n",
    "mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "mean_shap_importances = (\n",
    "    pd.DataFrame(mean_abs_shap, index=X_train.columns, columns=[\"SHAP Importance\"],)\n",
    "    .sort_values(\"SHAP Importance\", ascending=False)\n",
    "    .T\n",
    ")\n",
    "\n",
    "# Re-index according to the same ordering as for the Gini importances!\n",
    "mean_shap_importances = mean_shap_importances.reindex(mean_importances.index, axis=1)\n",
    "\n",
    "sns.boxplot(data=mean_shap_importances.iloc[:, :N_col], ax=ax3)\n",
    "ax3.set(ylabel=\"SHAP Importance\\n\")\n",
    "\n",
    "# VIFs\n",
    "\n",
    "# Re-index according to the same ordering as for the Gini importances!\n",
    "vifs = vifs.reindex(mean_importances.index, axis=1)\n",
    "\n",
    "sns.boxplot(data=vifs.iloc[:, :N_col], ax=ax4)\n",
    "ax4.set(ylabel=\"VIF\\n\")\n",
    "\n",
    "# Rotate the last x axis labels (the only visible ones).\n",
    "_ = axes[-1].set_xticklabels(axes[-1].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "for _ax in (ax, ax2, ax3, ax4):\n",
    "    _ax.grid(which=\"major\", alpha=0.3)\n",
    "    _ax.tick_params(labelleft=False)\n",
    "\n",
    "# fig.suptitle(\"Gini, PFI, SHAP, VIF\")\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.91)\n",
    "figure_saver.save_figure(fig, \"feature_importances_gini_pfi_shap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
