{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve previous results from the 'model' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_split_cache.load()\n",
    "results, rf = cross_val_cache.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values - via PBS array jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal SHAP values - single thread timing\n",
    "\n",
    "~ 2 s / sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([10, 30, 50, 100], [19.6, 57.2, 95, (3 * 60) + 18], marker=\"o\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"time (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values - see PBS (array) job folder 'shap'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "killed_jobs = []\n",
    "out_dir = PROJECT_DIR / Path(\"shap/output\")\n",
    "for out in tqdm(os.listdir(out_dir)):\n",
    "    with open(os.path.join(out_dir, out), \"r\") as f:\n",
    "        content = f.read()\n",
    "    if \"job killed\" in content:\n",
    "        killed_jobs.append(re.search(\"\\[(\\d+)\\]\", out).group(1))\n",
    "print(len(killed_jobs), \"killed jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted([int(k) for k in killed_jobs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actually load the SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 995  # Maximum job array index (inclusive).\n",
    "job_samples = 2000  # Samples per job.\n",
    "total_samples = (max_index + 1) * job_samples  # Sanity check.\n",
    "\n",
    "# Load the individual data chunks.\n",
    "shap_chunks = []\n",
    "for index in tqdm(range(max_index + 1), desc=\"Loading chunks\"):\n",
    "    shap_chunks.append(\n",
    "        SimpleCache(\n",
    "            f\"tree_path_dependent_shap_{index}_{job_samples}\",\n",
    "            cache_dir=os.path.join(CACHE_DIR, \"shap\"),\n",
    "            verbose=0,\n",
    "        ).load()\n",
    "    )\n",
    "shap_values = np.vstack(shap_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with figure_saver(\"SHAP\"):\n",
    "    shap.summary_plot(\n",
    "        shap_values,\n",
    "        shorten_columns(X_train[:total_samples]),\n",
    "        title=\"SHAP Feature Importances\",\n",
    "        show=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "mean_shap_importances = pd.DataFrame(\n",
    "    [shorten_features(X_train.columns), mean_abs_shap], index=[\"column\", \"shap\"]\n",
    ")\n",
    "mean_shap_importances = mean_shap_importances.T\n",
    "mean_shap_importances.sort_values(\"shap\", ascending=False, inplace=True)\n",
    "mean_shap_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction SHAP values - see PBS (array) job folder 'shap_interaction'!\n",
    "\n",
    "~ 150 s / sample !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "killed_jobs = []\n",
    "out_dir = PROJECT_DIR / Path(\"shap_interaction/output\")\n",
    "for out in tqdm(os.listdir(out_dir)):\n",
    "    with open(os.path.join(out_dir, out), \"r\") as f:\n",
    "        content = f.read()\n",
    "    if \"job killed\" in content:\n",
    "        killed_jobs.append(re.search(\"\\[(\\d+)\\]\", out).group(1))\n",
    "print(len(killed_jobs), \"killed jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted([int(k) for k in killed_jobs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 5999  # Maximum job array index (inclusive).\n",
    "job_samples = 50  # Samples per job.\n",
    "total_interact_samples = (max_index + 1) * job_samples\n",
    "\n",
    "shap_interact_cache = SimpleCache(\n",
    "    \"shap_interact_cache\", cache_dir=CACHE_DIR / Path(\"shap_interaction\")\n",
    ")\n",
    "\n",
    "\n",
    "@shap_interact_cache\n",
    "def load_shap_interact_from_chunks():\n",
    "    # Load the individual data chunks.\n",
    "    shap_interact_chunks = []\n",
    "    for index in tqdm(range(max_index + 1), desc=\"Loading chunks\"):\n",
    "        shap_interact_chunks.append(\n",
    "            SimpleCache(\n",
    "                f\"tree_path_dependent_shap_interact_{index}_{job_samples}\",\n",
    "                cache_dir=os.path.join(CACHE_DIR, \"shap_interaction\"),\n",
    "                verbose=0,\n",
    "            ).load()\n",
    "        )\n",
    "    return np.vstack(shap_interact_chunks)\n",
    "\n",
    "\n",
    "shap_interact_values = load_shap_interact_from_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with figure_saver(\"SHAP_interaction\"):\n",
    "    shap.summary_plot(\n",
    "        shap_interact_values,\n",
    "        shorten_columns(X_train[:total_interact_samples]),\n",
    "        title=\"SHAP Feature Interactions\",\n",
    "        show=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with figure_saver(\"SHAP_interaction_compact\"):\n",
    "    shap.summary_plot(\n",
    "        shap_interact_values,\n",
    "        shorten_columns(X_train[:total_interact_samples]),\n",
    "        title=\"SHAP Feature Interactions\",\n",
    "        show=False,\n",
    "        plot_type=\"compact_dot\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_interact = np.mean(np.abs(shap_interact_values), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.heatmap(\n",
    "    np.log(mean_interact),\n",
    "    square=True,\n",
    "    xticklabels=shorten_features(X_train.columns),\n",
    "    yticklabels=shorten_features(X_train.columns),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.xaxis.set_tick_params(rotation=90)\n",
    "ax.yaxis.set_tick_params(rotation=0)\n",
    "_ = fig.suptitle(\"log(SHAP Interaction Values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the most significant interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_interact_index(index, mean_interact):\n",
    "    indices = np.argsort(-mean_interact[index])\n",
    "    return indices[indices != index][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_mean_interact = mean_interact.copy()\n",
    "masked_mean_interact[np.triu_indices(mean_interact.shape[0])] = np.nan\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.heatmap(\n",
    "    np.log(masked_mean_interact),\n",
    "    square=True,\n",
    "    xticklabels=shorten_features(X_train.columns),\n",
    "    yticklabels=shorten_features(X_train.columns),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.xaxis.set_tick_params(rotation=90)\n",
    "ax.yaxis.set_tick_params(rotation=0)\n",
    "_ = fig.suptitle(\"log(SHAP Interaction Values)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_indices = np.tril_indices(mean_interact.shape[0])\n",
    "interact_values = mean_interact[interact_indices]\n",
    "\n",
    "interact_data = {}\n",
    "for i, j, interact_value in zip(*interact_indices, interact_values):\n",
    "    if i == j:\n",
    "        continue\n",
    "    interact_data[\n",
    "        tuple(\n",
    "            sorted(\n",
    "                (\n",
    "                    shorten_features(X_train.columns[i]),\n",
    "                    shorten_features(X_train.columns[j]),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ] = interact_value\n",
    "\n",
    "interact_data = pd.Series(interact_data).sort_values(ascending=False, inplace=False)\n",
    "interact_data[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the approximate and 'exact' interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 18\n",
    "header = f\"{'Feature':>{length}} : {'Approx':>{length}} {'Non Approx':>{length}}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for i in range(len(X_train.columns)):\n",
    "    approx = shap.common.approximate_interactions(\n",
    "        X_train.columns[i], shap_values, X_train[:total_samples]\n",
    "    )[0]\n",
    "    non_approx = get_highest_interact_index(i, mean_interact)\n",
    "    features = shorten_features(\n",
    "        X_train.columns[index] for index in (i, approx, non_approx)\n",
    "    )\n",
    "    print(f\"{features[0]:>{length}} : {features[1]:>{length}} {features[2]:>{length}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependence plots with the approximate dependence metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_dependence_plot(i, shap_values=shap_values, X=X_train[:total_samples]):\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    shap.dependence_plot(\n",
    "        i, shap_values, X, alpha=0.1, ax=ax,\n",
    "    )\n",
    "    figure_saver.save_figure(\n",
    "        fig,\n",
    "        f\"shap_dependence_{X_train.columns[i]}_approx\",\n",
    "        sub_directory=\"shap_dependence_approx\",\n",
    "    )\n",
    "\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=32) as executor:\n",
    "    plot_fs = []\n",
    "    for i in range(len(X_train.columns)):\n",
    "        plot_fs.append(executor.submit(approx_dependence_plot, i))\n",
    "\n",
    "    for plot_f in tqdm(\n",
    "        concurrent.futures.as_completed(plot_fs),\n",
    "        total=len(plot_fs),\n",
    "        desc=\"Plotting approx SHAP dependence plots\",\n",
    "    ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependence_plot(\n",
    "    i, shap_values=shap_values, X=X_train[:total_samples], mean_interact=mean_interact\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    shap.dependence_plot(\n",
    "        i,\n",
    "        shap_values,\n",
    "        X,\n",
    "        interaction_index=get_highest_interact_index(i, mean_interact),\n",
    "        alpha=0.1,\n",
    "        ax=ax,\n",
    "    )\n",
    "    figure_saver.save_figure(\n",
    "        fig, f\"shap_dependence_{X_train.columns[i]}\", sub_directory=\"shap_dependence\"\n",
    "    )\n",
    "\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=32) as executor:\n",
    "    plot_fs = []\n",
    "    for i in range(len(X_train.columns)):\n",
    "        plot_fs.append(executor.submit(dependence_plot, i))\n",
    "\n",
    "    for plot_f in tqdm(\n",
    "        concurrent.futures.as_completed(plot_fs),\n",
    "        total=len(plot_fs),\n",
    "        desc=\"Plotting SHAP dependence plots\",\n",
    "    ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP force plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### force_plot memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5e4 * (5e4 - 1) // 2) * 8 / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.n_jobs = 32\n",
    "N = int(1e3)\n",
    "shap.force_plot(\n",
    "    np.mean(rf.predict(X_train[:N])), shap_values[:N], shorten_columns(X_train[:N])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
