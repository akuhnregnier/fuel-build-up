{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "from common import _get_centres, _sci_format, _second_order_ale_quant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve previous results from the 'model' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_split_cache.load()\n",
    "results, rf = cross_val_cache.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALE Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ale_2d(predictor, train_set, features, bins=40, coverage=1):\n",
    "    if coverage < 1:\n",
    "        # This should be ok if `train_set` is randomised, as it usually is.\n",
    "        train_set = train_set[: int(train_set.shape[0] * coverage)]\n",
    "\n",
    "    ale, quantiles_list, samples_grid = _second_order_ale_quant(\n",
    "        predictor, train_set, features, bins=bins, return_samples_grid=True\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 4.5))\n",
    "\n",
    "    # Quantile axis transformation.\n",
    "    quantile_axis_list = (\"x\", \"y\")\n",
    "\n",
    "    plotting_quantiles_list = []\n",
    "    for axis, quantiles in zip((\"x\", \"y\"), quantiles_list):\n",
    "        if axis in quantile_axis_list:\n",
    "            inds = np.arange(len(quantiles))\n",
    "            plotting_quantiles_list.append(inds)\n",
    "            ax.set(**{f\"{axis}ticks\": _get_centres(inds)})\n",
    "            ax.set(\n",
    "                **{\n",
    "                    f\"{axis}ticklabels\": _sci_format(\n",
    "                        _get_centres(quantiles), scilim=0.6\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            plotting_quantiles_list.append(quantiles)\n",
    "\n",
    "    centres_list = [_get_centres(quantiles) for quantiles in plotting_quantiles_list]\n",
    "    n_x, n_y = 50, 50\n",
    "    x = np.linspace(centres_list[0][0], centres_list[0][-1], n_x)\n",
    "    y = np.linspace(centres_list[1][0], centres_list[1][-1], n_y)\n",
    "\n",
    "    X, Y = np.meshgrid(x, y, indexing=\"xy\")\n",
    "    ale_interp = scipy.interpolate.interp2d(centres_list[0], centres_list[1], ale.T)\n",
    "\n",
    "    CF = ax.contourf(X, Y, ale_interp(x, y), levels=30, alpha=0.85,)\n",
    "\n",
    "    # Do not autoscale, so that boxes at the edges (contourf only plots the bin\n",
    "    # centres, not their edges) don't enlarge the plot. Such boxes include markings for\n",
    "    # invalid cells, or hatched boxes for valid cells.\n",
    "    plt.autoscale(False)\n",
    "\n",
    "    # Add hatching for the significant cells. These have at least `min_samples` samples.\n",
    "    # By default, calculate this as the number of samples in each bin if everything was equally distributed, divided by 10.\n",
    "    min_samples = (train_set.shape[0] / reduce(mul, map(len, centres_list))) / 10\n",
    "    for i, j in zip(*np.where(samples_grid >= min_samples)):\n",
    "        ax.add_patch(\n",
    "            Rectangle(\n",
    "                [plotting_quantiles_list[0][i], plotting_quantiles_list[1][j]],\n",
    "                plotting_quantiles_list[0][i + 1] - plotting_quantiles_list[0][i],\n",
    "                plotting_quantiles_list[1][j + 1] - plotting_quantiles_list[1][j],\n",
    "                linewidth=0,\n",
    "                fill=None,\n",
    "                hatch=\".\",\n",
    "                alpha=0.4,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if np.any(ale.mask):\n",
    "        # Add rectangles to indicate cells without samples.\n",
    "        for i, j in zip(*np.where(ale.mask)):\n",
    "            ax.add_patch(\n",
    "                Rectangle(\n",
    "                    [plotting_quantiles_list[0][i], plotting_quantiles_list[1][j]],\n",
    "                    plotting_quantiles_list[0][i + 1] - plotting_quantiles_list[0][i],\n",
    "                    plotting_quantiles_list[1][j + 1] - plotting_quantiles_list[1][j],\n",
    "                    linewidth=1,\n",
    "                    edgecolor=\"k\",\n",
    "                    facecolor=\"none\",\n",
    "                    alpha=0.4,\n",
    "                )\n",
    "            )\n",
    "    fig.colorbar(CF, format=\"%.0e\", pad=0.03, aspect=32, shrink=0.85)\n",
    "    ax.set_xlabel(features[0])\n",
    "    ax.set_ylabel(features[1])\n",
    "    nbins_str = \"x\".join([str(len(centres)) for centres in centres_list])\n",
    "    fig.suptitle(\n",
    "        f\"Second-order ALE of {features[0]} and {features[1]}\\n\"\n",
    "        f\"Bins: {nbins_str} (Hatching: Sig., Boxes: Missing)\"\n",
    "    )\n",
    "    plt.subplots_adjust(top=0.89)\n",
    "    ax.xaxis.set_tick_params(rotation=45)\n",
    "\n",
    "    figure_saver.save_figure(fig, \"__\".join(features), sub_directory=\"2d_ale\")\n",
    "    return ale, quantiles_list, samples_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ale_and_get_importance(columns, model, train_set, coverage=0.02):\n",
    "    model.n_jobs = 8\n",
    "    ale, quantiles_list, samples_grid = save_ale_2d(\n",
    "        model.predict, train_set, columns, bins=20, coverage=coverage,\n",
    "    )\n",
    "    min_samples = (\n",
    "        train_set.shape[0] / reduce(mul, map(lambda x: len(x) - 1, quantiles_list))\n",
    "    ) / 10\n",
    "    #     try:\n",
    "    return np.ma.max(ale[samples_grid > min_samples]) - np.ma.min(\n",
    "        ale[samples_grid > min_samples]\n",
    "    )\n",
    "\n",
    "\n",
    "#     except:\n",
    "#         return None\n",
    "\n",
    "# XXX: Local trial\n",
    "# save_ale_and_get_importance(columns_list[0], rf, X_train)\n",
    "\n",
    "columns_list = list(combinations(X_train.columns, 2))\n",
    "\n",
    "print(\"Scattering\")\n",
    "rf_fut = client.scatter(rf, broadcast=True)\n",
    "X_fut = client.scatter(X_train, broadcast=True)\n",
    "print(\"Finished scattering\")\n",
    "\n",
    "ale_fs = [\n",
    "    client.submit(save_ale_and_get_importance, columns, rf_fut, X_fut)\n",
    "    for columns in columns_list\n",
    "]\n",
    "\n",
    "for ale_f in tqdm(\n",
    "    dask.distributed.as_completed(ale_fs),\n",
    "    total=len(ale_fs),\n",
    "    unit=\"plot\",\n",
    "    desc=\"Calculating 2D ALE plots\",\n",
    "    smoothing=0,\n",
    "    position=0,\n",
    "):\n",
    "    if ale_f.status == \"error\":\n",
    "        print(ale_f.result())\n",
    "\n",
    "\n",
    "ptp_values = {}\n",
    "\n",
    "for columns, ale_f in zip(columns_list, ale_fs):\n",
    "    ptp_values[columns] = ale_f.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore and count None values, then plot a histogram of the ptp values.\n",
    "filtered_columns_list = []\n",
    "filtered_ptp_values = []\n",
    "for columns, ptp in ptp_values.items():\n",
    "    if ptp is not None:\n",
    "        filtered_columns_list.append(columns)\n",
    "        filtered_ptp_values.append(ptp)\n",
    "\n",
    "np.asarray([ptp for ptp in ptp_values if ptp is not None])\n",
    "_ = plt.hist(filtered_ptp_values, bins=20)\n",
    "\n",
    "pdp_results = pd.Series(filtered_ptp_values, index=filtered_columns_list)\n",
    "pdp_results.sort_values(inplace=True, ascending=False)\n",
    "print(pdp_results.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
