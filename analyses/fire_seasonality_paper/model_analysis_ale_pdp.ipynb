{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve previous results from the 'model' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_split_cache.load()\n",
    "results, rf = cross_val_cache.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_client()\n",
    "# client = Client(n_workers=1, threads_per_worker=8, resources={'threads': 8})\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fut = client.scatter(rf, broadcast=True)\n",
    "X_fut = client.scatter(X_train, broadcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALE Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ale_plot_1d_with_ptp(\n",
    "    model,\n",
    "    X_train,\n",
    "    column,\n",
    "    n_jobs=8,\n",
    "    monte_carlo_rep=1000,\n",
    "    monte_carlo_ratio=100,\n",
    "    verbose=False,\n",
    "    monte_carlo=True,\n",
    "):\n",
    "    model.n_jobs = n_jobs\n",
    "    with parallel_backend(\"threading\", n_jobs=n_jobs):\n",
    "        fig, ax = plt.subplots(\n",
    "            figsize=(7.5, 4.5)\n",
    "        )  # Make sure plot is plotted onto a new figure.\n",
    "        out = ale_plot(\n",
    "            model,\n",
    "            X_train,\n",
    "            column,\n",
    "            bins=20,\n",
    "            monte_carlo=monte_carlo,\n",
    "            monte_carlo_rep=monte_carlo_rep,\n",
    "            monte_carlo_ratio=monte_carlo_ratio,\n",
    "            plot_quantiles=True,\n",
    "            quantile_axis=True,\n",
    "            rugplot_lim=0,\n",
    "            scilim=0.6,\n",
    "            return_data=True,\n",
    "            return_mc_data=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "    if monte_carlo:\n",
    "        fig, axes, data, mc_data = out\n",
    "    else:\n",
    "        fig, axes, data = out\n",
    "\n",
    "    for ax_key in (\"ale\", \"quantiles_x\"):\n",
    "        axes[ax_key].xaxis.set_tick_params(rotation=45)\n",
    "\n",
    "    sub_dir = \"ale\" if monte_carlo else \"ale_non_mc\"\n",
    "    figure_saver.save_figure(fig, column, sub_directory=sub_dir)\n",
    "\n",
    "    if monte_carlo:\n",
    "        mc_ales = np.array([])\n",
    "        for mc_q, mc_ale in mc_data:\n",
    "            mc_ales = np.append(mc_ales, mc_ale)\n",
    "        return np.ptp(data[1]), np.ptp(mc_ales)\n",
    "    else:\n",
    "        return np.ptp(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_ale_1d_cache = SimpleCache(\"world_ale_1d\", cache_dir=CACHE_DIR)\n",
    "\n",
    "# world_ale_1d_cache.clear()\n",
    "\n",
    "\n",
    "@world_ale_1d_cache\n",
    "def get_world_ale_1d():\n",
    "    n_threads = 8\n",
    "    ale_fs = [\n",
    "        client.submit(\n",
    "            save_ale_plot_1d_with_ptp,\n",
    "            model=rf_fut,\n",
    "            X_train=X_fut,\n",
    "            column=column,\n",
    "            n_jobs=n_threads,\n",
    "            monte_carlo_rep=1000,\n",
    "            resources={\"threads\": n_threads},\n",
    "        )\n",
    "        for column in X_train.columns\n",
    "    ]\n",
    "\n",
    "    for ale_f in tqdm(\n",
    "        dask.distributed.as_completed(ale_fs),\n",
    "        total=len(ale_fs),\n",
    "        unit=\"plot\",\n",
    "        desc=\"Calculating 1D ALE plots\",\n",
    "        smoothing=0,\n",
    "    ):\n",
    "        if ale_f.status == \"error\":\n",
    "            print(ale_f.result())\n",
    "\n",
    "    ptp_values = {}\n",
    "    mc_ptp_values = {}\n",
    "\n",
    "    for column, ale_f in zip(X_train.columns, ale_fs):\n",
    "        ptp_values[column], mc_ptp_values[column] = ale_f.result()\n",
    "    return ptp_values, mc_ptp_values\n",
    "\n",
    "\n",
    "ptp_values, mc_ptp_values = get_world_ale_1d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Non-MC runs manually (just for the plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_threads = 8\n",
    "ale_fs = [\n",
    "    client.submit(\n",
    "        save_ale_plot_1d_with_ptp,\n",
    "        model=rf_fut,\n",
    "        X_train=X_fut,\n",
    "        column=column,\n",
    "        n_jobs=n_threads,\n",
    "        monte_carlo=False,\n",
    "        resources={\"threads\": n_threads},\n",
    "    )\n",
    "    for column in X_train.columns\n",
    "]\n",
    "\n",
    "for ale_f in tqdm(\n",
    "    dask.distributed.as_completed(ale_fs),\n",
    "    total=len(ale_fs),\n",
    "    unit=\"plot\",\n",
    "    desc=\"Calculating 1D Non-MC ALE plots\",\n",
    "    smoothing=0,\n",
    "):\n",
    "    if ale_f.status == \"error\":\n",
    "        print(ale_f.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDP Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alepython.ale import _sci_format\n",
    "\n",
    "\n",
    "def save_pdp_plot_1d(model, X_train, column, n_jobs):\n",
    "    data_file = os.path.join(CACHE_DIR, \"pdp_data\", column)\n",
    "\n",
    "    if not os.path.isfile(data_file):\n",
    "        model.n_jobs = n_jobs\n",
    "        with parallel_backend(\"threading\", n_jobs=n_jobs):\n",
    "            pdp_isolate_out = pdp.pdp_isolate(\n",
    "                model=model,\n",
    "                dataset=X_train,\n",
    "                model_features=X_train.columns,\n",
    "                feature=column,\n",
    "                num_grid_points=20,\n",
    "            )\n",
    "        os.makedirs(os.path.dirname(data_file), exist_ok=True)\n",
    "        with open(data_file, \"wb\") as f:\n",
    "            pickle.dump((column, pdp_isolate_out), f, -1)\n",
    "    else:\n",
    "        with open(data_file, \"rb\") as f:\n",
    "            column, pdp_isolate_out = pickle.load(f)\n",
    "\n",
    "    # With ICEs.\n",
    "    fig_ice, axes_ice = pdp.pdp_plot(\n",
    "        pdp_isolate_out,\n",
    "        column,\n",
    "        plot_lines=True,\n",
    "        center=True,\n",
    "        frac_to_plot=1000,\n",
    "        x_quantile=True,\n",
    "        figsize=(7, 5),\n",
    "    )\n",
    "    axes_ice[\"pdp_ax\"].xaxis.set_tick_params(rotation=45)\n",
    "    figure_saver.save_figure(fig_ice, column, sub_directory=\"pdp\")\n",
    "\n",
    "    # Without ICEs.\n",
    "    fig_no_ice, ax = plt.subplots(figsize=(7.5, 4.5))\n",
    "    plt.plot(pdp_isolate_out.pdp - pdp_isolate_out.pdp[0], marker=\"o\")\n",
    "    plt.xticks(\n",
    "        ticks=range(len(pdp_isolate_out.pdp)),\n",
    "        labels=_sci_format(pdp_isolate_out.feature_grids, scilim=0.6),\n",
    "        rotation=45,\n",
    "    )\n",
    "    plt.xlabel(f\"{column}\")\n",
    "    plt.title(f\"PDP of feature '{column}'\\nBins: {len(pdp_isolate_out.pdp)}\")\n",
    "    plt.grid(alpha=0.4, linestyle=\"--\")\n",
    "    figure_saver.save_figure(fig_no_ice, column, sub_directory=\"pdp_no_ice\")\n",
    "    return (fig_ice, fig_no_ice), pdp_isolate_out, data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time save_pdp_plot_1d(rf, X_train, 'Dry Day Period -12 - 0 Month', n_jobs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequentially Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in tqdm(\n",
    "    X_train.columns, unit=\"plot\", desc=\"Calculating 1D PDP plots\", smoothing=0.05\n",
    "):\n",
    "    figs, pdp_isolate_out, data_file = save_pdp_plot_1d(rf, X_train, column, n_jobs=32)\n",
    "    for fig in figs:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Dask distributed Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_threads = 8\n",
    "pdp_fs = [\n",
    "    client.submit(\n",
    "        save_pdp_plot_1d,\n",
    "        model=rf_fut,\n",
    "        X_train=X_fut,\n",
    "        column=column,\n",
    "        n_jobs=n_threads,\n",
    "        resources={\"threads\": n_threads},\n",
    "    )\n",
    "    for column in X_train.columns\n",
    "]\n",
    "\n",
    "for pdp_f in tqdm(\n",
    "    dask.distributed.as_completed(pdp_fs),\n",
    "    total=len(pdp_fs),\n",
    "    unit=\"plot\",\n",
    "    desc=\"Calculating 1D PDP plots\",\n",
    "    smoothing=0.04,\n",
    "):\n",
    "    if pdp_f.status == \"error\":\n",
    "        print(pdp_f.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple ALE plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from alepython.ale import _sci_format, first_order_ale_quant\n",
    "\n",
    "\n",
    "def multi_ale_plot_1d(\n",
    "    model,\n",
    "    X_train,\n",
    "    columns,\n",
    "    fig_name,\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    title=None,\n",
    "    n_jobs=8,\n",
    "    verbose=False,\n",
    "):\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(7.5, 4.5)\n",
    "    )  # Make sure plot is plotted onto a new figure.\n",
    "    model.n_jobs = n_jobs\n",
    "    with parallel_backend(\"threading\", n_jobs=n_jobs):\n",
    "        quantile_list = []\n",
    "        ale_list = []\n",
    "        for feature in tqdm(\n",
    "            columns, desc=\"Calculating feature ALEs\", disable=not verbose\n",
    "        ):\n",
    "            quantiles, ale = first_order_ale_quant(\n",
    "                model.predict, X_train, feature, bins=20\n",
    "            )\n",
    "            quantile_list.append(quantiles)\n",
    "            ale_list.append(ale)\n",
    "\n",
    "    # Construct quantiles from the individual quantiles, minimising the amount of interpolation.\n",
    "    combined_quantiles = np.vstack([quantiles[None] for quantiles in quantile_list])\n",
    "\n",
    "    final_quantiles = np.mean(combined_quantiles, axis=0)\n",
    "    # Account for extrema.\n",
    "    final_quantiles[0] = np.min(combined_quantiles)\n",
    "    final_quantiles[-1] = np.max(combined_quantiles)\n",
    "\n",
    "    mod_quantiles = np.arange(len(quantiles))\n",
    "    for feature, quantiles, ale in zip(columns, quantile_list, ale_list):\n",
    "        # Interpolate each of the quantiles relative to the accumulated final quantiles.\n",
    "        ax.plot(\n",
    "            np.interp(quantiles, final_quantiles, mod_quantiles),\n",
    "            ale,\n",
    "            marker=\"o\",\n",
    "            ms=3,\n",
    "            label=feature,\n",
    "        )\n",
    "\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_xticks(mod_quantiles)\n",
    "    ax.set_xticklabels(_sci_format(final_quantiles, scilim=0.6))\n",
    "    ax.xaxis.set_tick_params(rotation=45)\n",
    "    ax.grid(alpha=0.4, linestyle=\"--\")\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    figure_saver.save_figure(fig, fig_name, sub_directory=\"multi_ale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in tqdm(\n",
    "    (\"Dry Day Period\", \"SIF\", \"FAPAR\", \"LAI\"), desc=\"Multiple shift ALE plots\"\n",
    "):\n",
    "    multi_ale_plot_1d(\n",
    "        rf,\n",
    "        X_train,\n",
    "        (f\"{feature}\", *(f\"{feature} {m} Month\" for m in (-1, -3, -6, -9))),\n",
    "        f'{feature.replace(\" \", \"_\").lower()}_ale_shifts',\n",
    "        n_jobs=32,\n",
    "        verbose=True,\n",
    "        xlabel=f\"{feature}\",\n",
    "        title=f\"First-order ALE for {feature}\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
