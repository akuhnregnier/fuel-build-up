{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "\n",
    "import iris\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from wildfires.analysis import *\n",
    "from wildfires.data import *\n",
    "from wildfires.logging_config import enable_logging\n",
    "from wildfires.qstat import *\n",
    "from wildfires.utils import *\n",
    "\n",
    "if \"TQDMAUTO\" in os.environ:\n",
    "    from tqdm.auto import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "\n",
    "enable_logging(\"jupyter\")\n",
    "figure_saver = FigureSaver(directories=Path(\"~\") / \"tmp\" / \"interp_comp\", debug=True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Collapsing a non-contiguous coordinate.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*DEFAULT_SPHERICAL_EARTH_RADIUS.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*guessing contiguous bounds.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*divide by zero.*\")\n",
    "\n",
    "mpl.rc(\"figure\", figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_months = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_fit(t, params):\n",
    "    \"\"\"Sine-based fitting including offset.\n",
    "        \n",
    "    Args:\n",
    "        t (int): Time index.\n",
    "        params (array-like): \n",
    "            0th - offset\n",
    "            1th - gradient\n",
    "            (2j, 2j+1) entries - jth component amplitude and phase, j <= 1.            \n",
    "            \n",
    "    Returns:\n",
    "        float: Fitted function value at `t`.\n",
    "    \n",
    "    \"\"\"\n",
    "    t = np.asarray(t, dtype=np.float64)\n",
    "    output = np.zeros_like(t, dtype=np.float64)\n",
    "    output += params[0]\n",
    "    output += params[1] * t\n",
    "    for (j, (amplitude, phase)) in enumerate(zip(params[2::2], params[3::2])):\n",
    "        j += 1\n",
    "        output += amplitude * np.sin((2 * np.pi * j * t / 12) + phase)\n",
    "    return output\n",
    "\n",
    "\n",
    "def min_fit(x, *args):\n",
    "    \"\"\"Function to be minimised.\n",
    "    \n",
    "    Args:\n",
    "        x (array-like): Fit parameters.\n",
    "        args: Month indices and corresponding data to fit to.\n",
    "        \n",
    "    Returns:\n",
    "        float: MSE fit error.\n",
    "    \n",
    "    \"\"\"\n",
    "    ts = args[0]\n",
    "    fit_data = args[1]\n",
    "    return np.sum((fit_data - harmonic_fit(ts, x)) ** 2.0)\n",
    "\n",
    "\n",
    "def persistent_gap_filling(cube, combined_mask, thres=0.5):\n",
    "    \"\"\"Fill gaps >= (thres * 100)% of months with minimum value at that location.\"\"\"\n",
    "    cube = cube.copy()\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    nr_inval_cube = cube.copy(\n",
    "        data=np.ma.MaskedArray(\n",
    "            cube.data.mask, mask=match_shape(combined_mask, cube.shape),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    min_cube = cube.collapsed(\"time\", iris.analysis.MIN)\n",
    "\n",
    "    # Month numbers in [1, 12].\n",
    "    month_numbers = cube.coord(\"month_number\").points\n",
    "\n",
    "    for month_number in tqdm(range(1, 13), desc=\"Months\"):\n",
    "        extracted = iris.Constraint(month_number=month_number).extract(nr_inval_cube)\n",
    "        missing_frac = np.sum(extracted.data, axis=0) / extracted.shape[0]\n",
    "        persistent = ((missing_frac + 1e-5) >= thres).data\n",
    "        persistent[combined_mask] = False\n",
    "\n",
    "        for month_index in np.where(month_numbers == month_number)[0]:\n",
    "            month_data = cube.data[month_index]\n",
    "\n",
    "            fill_mask = persistent & cube.data.mask[month_index]\n",
    "            month_data[fill_mask] = min_cube.data[fill_mask]\n",
    "\n",
    "            cube.data[month_index] = month_data\n",
    "\n",
    "    return cube\n",
    "\n",
    "\n",
    "def _season_fill(fill_locs, data, n):\n",
    "    ts = np.arange(data.shape[0])\n",
    "\n",
    "    for xi, yi in zip(*np.where(fill_locs)):\n",
    "        sel = data[:, xi, yi]\n",
    "        # Execute minimisation.\n",
    "        res = minimize(min_fit, np.zeros(n), (ts, sel))\n",
    "        # Replace masked elements with function fit values.\n",
    "        sel[sel.mask] = harmonic_fit(ts, res.x)[sel.mask]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def season_model_filling(cube, n=8):\n",
    "    cube = cube.copy()\n",
    "\n",
    "    # Fill where there is some valid data, but not only valid data, since there would\n",
    "    # be nothing to fill in the latter case.\n",
    "    fill_locs = np.any(~cube.data.mask, axis=0) & (~np.all(~cube.data.mask, axis=0))\n",
    "\n",
    "    # Partition the rows of the array in chunks to be processed.\n",
    "    ncpus = get_ncpus()\n",
    "    nrows = cube.shape[1]\n",
    "\n",
    "    chunk_edges = np.unique(np.append(np.arange(0, nrows, 2, dtype=np.int64), nrows,))\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=ncpus) as executor:\n",
    "        fs = []\n",
    "        processed_slices = []\n",
    "        for chunk_s, chunk_e in zip(chunk_edges[:-1], chunk_edges[1:]):\n",
    "            chunk_slice = slice(chunk_s, chunk_e)\n",
    "            if not np.any(fill_locs[chunk_slice]):\n",
    "                # Skip those slices without anything to fill.\n",
    "                continue\n",
    "            processed_slices.append(chunk_slice)\n",
    "            fs.append(\n",
    "                executor.submit(\n",
    "                    _season_fill, fill_locs[chunk_slice], cube.data[:, chunk_slice], n\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for f in tqdm(\n",
    "            concurrent.futures.as_completed(fs),\n",
    "            desc=\"Season model filling\",\n",
    "            total=len(fs),\n",
    "        ):\n",
    "            pass\n",
    "\n",
    "        for f, chunk_slice, in zip(fs, processed_slices):\n",
    "            cube.data[:, chunk_slice] = f.result()\n",
    "\n",
    "    return cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = (\"SWI(1)\", \"FAPAR\", \"LAI\", \"VOD Ku-band\", \"SIF\")\n",
    "datasets = Datasets(\n",
    "    (Copernicus_SWI(), MOD15A2H_LAI_fPAR(), VODCA(), GlobFluo_SIF())\n",
    ").select_variables(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeperiod = (datetime(2010, 1, 1, 0, 0), datetime(2015, 1, 1, 0, 0))\n",
    "period_str = f\"{timeperiod[0]:%Y-%m} - {timeperiod[1]:%Y-%m}\"\n",
    "orig_datasets = datasets.copy()\n",
    "for dataset in orig_datasets:\n",
    "    datasets.add(dataset.get_temporally_interpolated_dataset(timeperiod, 3))\n",
    "for dataset in datasets:\n",
    "    dataset.limit_months(*timeperiod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.show(\"pretty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate climatologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatologies = Datasets(\n",
    "    [\n",
    "        dataset.get_climatology_dataset(dataset.min_time, dataset.max_time)\n",
    "        for dataset in tqdm(\n",
    "            datasets.select_variables(variables, inplace=False),\n",
    "            desc=\"Getting climatologies\",\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_masks = []\n",
    "\n",
    "for var in tqdm(variables, desc=\"Variable\"):\n",
    "    cube = datasets.select_variables(var, inplace=False).cube.copy()\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    # Ignore areas that are always masked, e.g. water.\n",
    "    ignore_mask = np.all(cube.data.mask, axis=0)\n",
    "\n",
    "    # Also ignore those areas with low data availability.\n",
    "    ignore_mask |= np.sum(cube.data.mask, axis=0) > (\n",
    "        5 * 6 + 1  # Up to 6 months for each of the 5 complete years.  # Extra January.\n",
    "    )\n",
    "\n",
    "    total_masks.append(ignore_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_mask = reduce(\n",
    "    np.logical_or, [regrid(dummy_lat_lon_cube(mask)).data for mask in total_masks]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply combined mask to 'fresh' datasets and get data filled using minima and season-trend model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_datasets = Datasets(\n",
    "    (Copernicus_SWI(), MOD15A2H_LAI_fPAR(), VODCA(), GlobFluo_SIF())\n",
    ").select_variables(variables)\n",
    "\n",
    "# Select correct time period and regrid to common grid.\n",
    "for dataset in masked_datasets:\n",
    "    dataset.limit_months(*timeperiod)\n",
    "    dataset.regrid()\n",
    "\n",
    "# Apply the combined mask.\n",
    "masked_datasets.apply_masks(combined_mask)\n",
    "\n",
    "# Retrieve the filled dataset for later comparison.\n",
    "processed_datasets = Datasets(\n",
    "    [dataset.get_persistent_season_trend_dataset() for dataset in masked_datasets]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_filled_cubes = {}\n",
    "model_filled_cubes = {}\n",
    "\n",
    "for var in tqdm(variables, desc=\"Filling variables\"):\n",
    "    cube = regrid(datasets.select_variables(var, inplace=False).cube.copy())\n",
    "\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    cube.data.mask |= match_shape(combined_mask, cube.shape)\n",
    "\n",
    "    gap_filled_cube = persistent_gap_filling(cube, combined_mask)\n",
    "    model_filled_cube = season_model_filling(gap_filled_cube)\n",
    "\n",
    "    gap_filled_cubes[var] = gap_filled_cube\n",
    "    model_filled_cubes[var] = model_filled_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function comparison - both model-filled datasets should be equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in variables:\n",
    "    orig_cube = masked_datasets.select_variables(var, inplace=False).cube\n",
    "    old_cube = model_filled_cubes[var]\n",
    "    new_cube = processed_datasets.select_variables(var + \" 50P 4k\", inplace=False).cube\n",
    "\n",
    "    print(var, new_cube == old_cube)\n",
    "    cube_plotting(old_cube, title=f\"{var} old\\n{period_str}\")\n",
    "    cube_plotting(new_cube, title=f\"{var} new\\n{period_str}\")\n",
    "    mean_diffs = np.mean(np.abs(old_cube.data - new_cube.data), axis=0)\n",
    "    max_vals = np.abs(np.max(orig_cube.data, axis=0))\n",
    "\n",
    "    cube_plotting(mean_diffs / max_vals, title=\"Relative Mean |Diffs|\")\n",
    "    for i in (mean_diffs / max_vals).ravel().argsort(fill_value=0)[::-1][:20]:\n",
    "        plt.figure()\n",
    "        s = (slice(None), *np.unravel_index(i, old_cube.shape[1:]))\n",
    "        plt.plot(orig_cube.data[s], label=\"orig\", marker=\"x\")\n",
    "        plt.plot(old_cube.data[s], label=\"old\")\n",
    "        plt.plot(new_cube.data[s], label=\"new\")\n",
    "        plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks (how many missing samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = figure_saver(sub_directory=\"masks\")\n",
    "\n",
    "for var in tqdm(variables, desc=\"Variable\"):\n",
    "    cube = datasets.select_variables(var, inplace=False).cube.copy()\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    # Ignore areas that are always masked, e.g. water.\n",
    "    ignore_mask = np.all(cube.data.mask, axis=0)\n",
    "\n",
    "    fig = cube_plotting(\n",
    "        np.ma.MaskedArray(\n",
    "            cube.data.mask.astype(\"float64\"),\n",
    "            mask=match_shape(ignore_mask, cube.data.shape),\n",
    "        ),\n",
    "        title=f\"{var}\\n{period_str}\",\n",
    "        boundaries=np.linspace(0, 1, 6),\n",
    "    )\n",
    "    saver.save_figure(fig, f\"{var} masked samples\")\n",
    "\n",
    "    # Missing fraction by month.\n",
    "    counts = {}\n",
    "    for month_number in tqdm(range(1, 13), desc=\"Months\"):\n",
    "        extracted = iris.Constraint(month_number=month_number).extract(cube)\n",
    "        ext_mask = np.sum(extracted.data.mask, axis=0)\n",
    "\n",
    "        fig = cube_plotting(\n",
    "            np.ma.MaskedArray(ext_mask, mask=match_shape(ignore_mask, ext_mask.shape),),\n",
    "            title=f\"{var} month {month_number}\\n{period_str}\",\n",
    "        )\n",
    "        saver.save_figure(fig, f\"{var} month {month_number} masked samples\")\n",
    "\n",
    "        selected = ext_mask[~match_shape(ignore_mask, ext_mask.shape)]\n",
    "        counts[month_number] = np.sum(selected)\n",
    "\n",
    "    with saver(f\"{var} masked months\"):\n",
    "        pd.Series(counts).to_frame(\"masked months\").plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore locations with too much missing data - Resulting Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_str = f\"{timeperiod[0]:%Y-%m} - {timeperiod[1]:%Y-%m}\"\n",
    "\n",
    "saver = figure_saver(sub_directory=\"sel masks\")\n",
    "\n",
    "for var in tqdm(variables, desc=\"Variable\"):\n",
    "    cube = datasets.select_variables(var, inplace=False).cube.copy()\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    # Ignore areas that are always masked, e.g. water.\n",
    "    ignore_mask = np.all(cube.data.mask, axis=0)\n",
    "\n",
    "    # Also ignore those areas with low data availability.\n",
    "    ignore_mask |= np.sum(cube.data.mask, axis=0) > (\n",
    "        5 * 6 + 1  # Up to 6 months for each of the 5 complete years.  # Extra January.\n",
    "    )\n",
    "\n",
    "    nr_inval_cube = cube.copy(\n",
    "        data=np.ma.MaskedArray(\n",
    "            cube.data.mask.copy(), mask=match_shape(ignore_mask, cube.shape),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    nr_inval_cube = nr_inval_cube.collapsed(\"time\", iris.analysis.SUM)\n",
    "\n",
    "    fig = cube_plotting(\n",
    "        nr_inval_cube,\n",
    "        title=f\"{var}\\n{period_str}\",\n",
    "        colorbar_kwargs={\"label\": \"nr. invalid\"},\n",
    "    )\n",
    "    saver.save_figure(fig, f\"{var} nr masked samples\")\n",
    "\n",
    "    # Missing fraction by month.\n",
    "    counts = {}\n",
    "    for month_number in tqdm(range(1, 13), desc=\"Months\"):\n",
    "        extracted = iris.Constraint(month_number=month_number).extract(cube)\n",
    "        ext_mask = np.sum(extracted.data.mask, axis=0)\n",
    "        selected = ext_mask[~match_shape(ignore_mask, ext_mask.shape)]\n",
    "        counts[month_number] = np.sum(selected)\n",
    "\n",
    "    with saver(f\"{var} masked months\"):\n",
    "        pd.Series(counts).to_frame(\"masked months\").plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot combined ignore masks.\n",
    "fig = cube_plotting(\n",
    "    combined_mask,\n",
    "    title=f\"Combined Mask\\n{period_str}\",\n",
    "    colorbar_kwargs={\"label\": \"masked\"},\n",
    "    boundaries=np.linspace(0, 1, 3),\n",
    "    fig=plt.figure(figsize=(18, 9)),\n",
    ")\n",
    "figure_saver.save_figure(fig, f\"combined mask samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_dataset = GFEDv4()\n",
    "ba_dataset.limit_months(*timeperiod)\n",
    "mean_ba = ba_dataset.cube.collapsed(\"time\", iris.analysis.MEAN)\n",
    "mean_ba.data.mask = ~get_land_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = cube_plotting(\n",
    "    mean_ba,\n",
    "    title=f\"Mean BA\\n{period_str}\",\n",
    "    colorbar_kwargs={\"label\": \"BA\", \"format\": \"%0.0e\"},\n",
    "    cmap=\"YlOrRd\",\n",
    "    fig=plt.figure(figsize=(18, 9)),\n",
    "    boundaries=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    extend=\"min\",\n",
    ")\n",
    "figure_saver.save_figure(fig, f\"burned area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_mean_ba = mean_ba.copy()\n",
    "masked_mean_ba.data.mask = combined_mask\n",
    "fig = cube_plotting(\n",
    "    masked_mean_ba,\n",
    "    title=f\"Mean BA\\n{period_str}\",\n",
    "    colorbar_kwargs={\"label\": \"BA\", \"format\": \"%0.0e\"},\n",
    "    cmap=\"YlOrRd\",\n",
    "    fig=plt.figure(figsize=(18, 9)),\n",
    "    boundaries=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    extend=\"min\",\n",
    ")\n",
    "figure_saver.save_figure(fig, f\"combined mask burned area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined mask - missing NH samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = figure_saver(sub_directory=\"comb mask NH\")\n",
    "\n",
    "for var in tqdm(variables, desc=\"Variable\"):\n",
    "    cube = regrid(datasets.select_variables(var, inplace=False).cube.copy())\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    nr_inval_cube = cube.copy(\n",
    "        data=np.ma.MaskedArray(\n",
    "            cube.data.mask, mask=match_shape(combined_mask, cube.shape),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    nr_inval_cube = iris.Constraint(\n",
    "        coord_values={\"latitude\": lambda cell: 0 < cell}\n",
    "    ).extract(nr_inval_cube)\n",
    "\n",
    "    fig = cube_plotting(\n",
    "        nr_inval_cube.collapsed(\"time\", iris.analysis.SUM),\n",
    "        title=f\"{var}\\n{period_str}\",\n",
    "        colorbar_kwargs={\"label\": \"nr. invalid\"},\n",
    "    )\n",
    "    saver.save_figure(fig, f\"{var} nr masked samples\")\n",
    "\n",
    "    # Missing fraction by month.\n",
    "    counts = {}\n",
    "    for month_number in tqdm(range(1, 13), desc=\"Months\"):\n",
    "        extracted = iris.Constraint(month_number=month_number).extract(nr_inval_cube)\n",
    "        counts[month_number] = np.sum(extracted.data)\n",
    "\n",
    "    with saver(f\"{var} masked months\"):\n",
    "        pd.Series(counts).to_frame(\"masked months\").plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined mask - missing SH samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = figure_saver(sub_directory=\"comb mask SH\")\n",
    "\n",
    "for var in tqdm(variables, desc=\"Variable\"):\n",
    "    cube = regrid(datasets.select_variables(var, inplace=False).cube.copy())\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    nr_inval_cube = cube.copy(\n",
    "        data=np.ma.MaskedArray(\n",
    "            cube.data.mask, mask=match_shape(combined_mask, cube.shape),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    nr_inval_cube = iris.Constraint(\n",
    "        coord_values={\"latitude\": lambda cell: 0 > cell}\n",
    "    ).extract(nr_inval_cube)\n",
    "\n",
    "    fig = cube_plotting(\n",
    "        nr_inval_cube.collapsed(\"time\", iris.analysis.SUM),\n",
    "        title=f\"{var}\\n{period_str}\",\n",
    "        colorbar_kwargs={\"label\": \"nr. invalid\"},\n",
    "    )\n",
    "    saver.save_figure(fig, f\"{var} nr masked samples\")\n",
    "\n",
    "    # Missing fraction by month.\n",
    "    counts = {}\n",
    "    for month_number in tqdm(range(1, 13), desc=\"Months\"):\n",
    "        extracted = iris.Constraint(month_number=month_number).extract(nr_inval_cube)\n",
    "        counts[month_number] = np.sum(extracted.data)\n",
    "\n",
    "    with saver(f\"{var} masked months\"):\n",
    "        pd.Series(counts).to_frame(\"masked months\").plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimisation(ts, sel, n=8, plot=False, sel2=None, sel3=None):\n",
    "    # Execute minimisation.\n",
    "    res = minimize(min_fit, np.zeros(n), (ts, sel))\n",
    "    rmse = np.sqrt(res.fun)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(ts, sel, c=\"C3\", label=\"persistent gap fill\")\n",
    "        if sel2 is not None:\n",
    "            ax.plot(ts, sel2, c=\"C0\", linestyle=\"-.\", marker=\"x\", label=\"raw\")\n",
    "\n",
    "        if sel3 is not None:\n",
    "            ax.plot(\n",
    "                ts,\n",
    "                sel3,\n",
    "                c=\"C4\",\n",
    "                linestyle=\"--\",\n",
    "                marker=\"o\",\n",
    "                zorder=0,\n",
    "                label=\"season model fill\",\n",
    "            )\n",
    "\n",
    "        # Prevent further autoscaling.\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.autoscale(False)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "        ax.vlines(\n",
    "            np.arange(0.5, 62, 12),\n",
    "            ymin=-100,\n",
    "            ymax=100,\n",
    "            colors=\"C3\",\n",
    "            zorder=3,\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.4,\n",
    "        )\n",
    "        ax.plot(ts, harmonic_fit(ts, res.x), c=\"C1\", linestyle=\"--\")\n",
    "        ax.set_title(\n",
    "            f\"invalid: {np.sum(sel2.mask)}, gap filled: {np.sum(sel2.mask) - np.sum(sel.mask)}, model filled: {np.sum(sel.mask) - np.sum(sel3.mask)}, RMSE: {rmse}\"\n",
    "        )\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Northern masked timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = figure_saver(sub_directory=\"masked_timeseries\")\n",
    "\n",
    "for var in variables:\n",
    "    cube = regrid(datasets.select_variables(var, inplace=False).cube.copy())\n",
    "\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    cube.data.mask |= match_shape(combined_mask, cube.shape)\n",
    "\n",
    "    gap_filled_cube = gap_filled_cubes[var]\n",
    "    model_filled_cube = model_filled_cubes[var]\n",
    "\n",
    "    constraint = iris.Constraint(\n",
    "        coord_values={\"latitude\": lambda cell: (0 < cell) and (cell < 90)}\n",
    "    )\n",
    "\n",
    "    extracted = constraint.extract(cube)\n",
    "    extracted_filled = constraint.extract(gap_filled_cube)\n",
    "    model_filled_extracted = constraint.extract(model_filled_cube)\n",
    "\n",
    "    cube_plotting(extracted)\n",
    "\n",
    "    xi, yi = np.where(np.any(~extracted.data.mask, axis=0))\n",
    "\n",
    "    class StopPlotting(Exception):\n",
    "        pass\n",
    "\n",
    "    valid_loc = np.sum(np.any(~extracted.data.mask, axis=0))\n",
    "    print(\"number of valid locations:\", valid_loc)\n",
    "\n",
    "    count = 0\n",
    "    thres = 100  # Number of plots to carry out.\n",
    "\n",
    "    # Randomly allow plotting to take place to achieve approx. the intended number.\n",
    "    chance = thres / valid_loc\n",
    "\n",
    "    rng = np.random.RandomState(1)\n",
    "\n",
    "    latitudes = extracted.coord(\"latitude\").points\n",
    "    valid_lats = latitudes[np.any(extracted.data.mask, axis=(0, 2))]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax_cb = make_axes_locatable(ax).new_horizontal(size=\"3%\", pad=0.1)\n",
    "    norm = mpl.colors.Normalize(\n",
    "        vmin=np.min(valid_lats), vmax=np.max(valid_lats), clip=True\n",
    "    )\n",
    "    cb = mpl.colorbar.ColorbarBase(\n",
    "        ax_cb, cmap=mpl.cm.viridis, orientation=\"vertical\", norm=norm,\n",
    "    )\n",
    "    fig.add_axes(ax_cb)\n",
    "\n",
    "    try:\n",
    "        for i, j in zip(tqdm(xi, desc=\"Valid positions\"), yi):\n",
    "            sel = extracted.data[:, i, j]\n",
    "\n",
    "            if rng.random() > chance:\n",
    "                # Skip positions at random to only plot the desired number on average.\n",
    "                continue\n",
    "\n",
    "            ax.plot(\n",
    "                range(1, extracted.shape[0] + 1),\n",
    "                sel,\n",
    "                c=mpl.cm.viridis(norm(latitudes[i])),\n",
    "                alpha=0.4,\n",
    "                zorder=4,\n",
    "            )\n",
    "            count += 1\n",
    "\n",
    "            # Disable hard exit.\n",
    "            if (count > thres) and False:\n",
    "                raise StopPlotting()\n",
    "    except StopPlotting:\n",
    "        pass\n",
    "\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.vlines(\n",
    "        np.arange(0.5, 62, 12),\n",
    "        ymin=-100,\n",
    "        ymax=100,\n",
    "        colors=\"C3\",\n",
    "        zorder=3,\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.4,\n",
    "    )\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "    # Plot individual timeseries with seasonal fits.\n",
    "\n",
    "    count = 0\n",
    "    limit = 30\n",
    "\n",
    "    for i in np.random.permutation(np.arange(xi.size)):\n",
    "        sel = extracted_filled.data[:, xi[i], yi[i]]\n",
    "        sel2 = extracted.data[:, xi[i], yi[i]]\n",
    "        sel3 = model_filled_extracted.data[:, xi[i], yi[i]]\n",
    "\n",
    "        if np.sum(sel2.mask) < 20:\n",
    "            # Ignore good timeseries.\n",
    "            continue\n",
    "        elif (np.sum(sel.mask) - np.sum(sel3.mask)) < 1:\n",
    "            # Ignore timeseries that do not contain model-filled samples.\n",
    "            continue\n",
    "        else:\n",
    "            count += 1\n",
    "            if count > limit:\n",
    "                break\n",
    "\n",
    "        ts = np.arange(1, sel.size + 1)\n",
    "        minimisation(ts, sel, plot=True, sel2=sel2, sel3=sel3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Southern masked timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = figure_saver(sub_directory=\"masked_timeseries\")\n",
    "\n",
    "for var in variables:\n",
    "    cube = regrid(datasets.select_variables(var, inplace=False).cube.copy())\n",
    "\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    cube.data.mask |= match_shape(combined_mask, cube.shape)\n",
    "\n",
    "    gap_filled_cube = gap_filled_cubes[var]\n",
    "    model_filled_cube = model_filled_cubes[var]\n",
    "\n",
    "    constraint = iris.Constraint(\n",
    "        coord_values={\"latitude\": lambda cell: (-90 < cell) and (cell < 0)}\n",
    "    )\n",
    "\n",
    "    extracted = constraint.extract(cube)\n",
    "    extracted_filled = constraint.extract(gap_filled_cube)\n",
    "    model_filled_extracted = constraint.extract(model_filled_cube)\n",
    "\n",
    "    cube_plotting(extracted)\n",
    "\n",
    "    xi, yi = np.where(np.any(~extracted.data.mask, axis=0))\n",
    "\n",
    "    class StopPlotting(Exception):\n",
    "        pass\n",
    "\n",
    "    valid_loc = np.sum(np.any(~extracted.data.mask, axis=0))\n",
    "    print(\"number of valid locations:\", valid_loc)\n",
    "\n",
    "    count = 0\n",
    "    thres = 100  # Number of plots to carry out.\n",
    "\n",
    "    # Randomly allow plotting to take place to achieve approx. the intended number.\n",
    "    chance = thres / valid_loc\n",
    "\n",
    "    rng = np.random.RandomState(1)\n",
    "\n",
    "    latitudes = extracted.coord(\"latitude\").points\n",
    "    valid_lats = latitudes[np.any(extracted.data.mask, axis=(0, 2))]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax_cb = make_axes_locatable(ax).new_horizontal(size=\"3%\", pad=0.1)\n",
    "    norm = mpl.colors.Normalize(\n",
    "        vmin=np.min(valid_lats), vmax=np.max(valid_lats), clip=True\n",
    "    )\n",
    "    cb = mpl.colorbar.ColorbarBase(\n",
    "        ax_cb, cmap=mpl.cm.viridis, orientation=\"vertical\", norm=norm,\n",
    "    )\n",
    "    fig.add_axes(ax_cb)\n",
    "\n",
    "    try:\n",
    "        for i, j in zip(tqdm(xi, desc=\"Valid positions\"), yi):\n",
    "            sel = extracted.data[:, i, j]\n",
    "\n",
    "            if rng.random() > chance:\n",
    "                # Skip positions at random to only plot the desired number on average.\n",
    "                continue\n",
    "\n",
    "            ax.plot(\n",
    "                range(1, extracted.shape[0] + 1),\n",
    "                sel,\n",
    "                c=mpl.cm.viridis(norm(latitudes[i])),\n",
    "                alpha=0.4,\n",
    "                zorder=4,\n",
    "            )\n",
    "            count += 1\n",
    "\n",
    "            # Disable hard exit.\n",
    "            if (count > thres) and False:\n",
    "                raise StopPlotting()\n",
    "    except StopPlotting:\n",
    "        pass\n",
    "\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.vlines(\n",
    "        np.arange(0.5, 62, 12),\n",
    "        ymin=-100,\n",
    "        ymax=100,\n",
    "        colors=\"C3\",\n",
    "        zorder=3,\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.4,\n",
    "    )\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "    # Plot individual timeseries with seasonal fits.\n",
    "\n",
    "    count = 0\n",
    "    limit = 30\n",
    "\n",
    "    for i in np.random.permutation(np.arange(xi.size)):\n",
    "        sel = extracted_filled.data[:, xi[i], yi[i]]\n",
    "        sel2 = extracted.data[:, xi[i], yi[i]]\n",
    "        sel3 = model_filled_extracted.data[:, xi[i], yi[i]]\n",
    "\n",
    "        if np.sum(sel2.mask) < 20:\n",
    "            # Ignore good timeseries.\n",
    "            continue\n",
    "        elif (np.sum(sel.mask) - np.sum(sel3.mask)) < 1:\n",
    "            # Ignore timeseries that do not contain model-filled samples.\n",
    "            continue\n",
    "        else:\n",
    "            count += 1\n",
    "            if count > limit:\n",
    "                break\n",
    "\n",
    "        ts = np.arange(1, sel.size + 1)\n",
    "        minimisation(ts, sel, plot=True, sel2=sel2, sel3=sel3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent gaps - 50% or more data missing for a given month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = figure_saver(sub_directory=\"persistent_gaps\")\n",
    "\n",
    "cmap = colors.ListedColormap([\"blue\", \"red\"])\n",
    "boundaries = np.linspace(0, 1, 3)\n",
    "norm = colors.BoundaryNorm(boundaries, cmap.N, clip=True)\n",
    "\n",
    "for var in tqdm(variables, desc=\"Variables\"):\n",
    "    cube = regrid(datasets.select_variables(var, inplace=False).cube.copy())\n",
    "\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    nr_inval_cube = cube.copy(\n",
    "        data=np.ma.MaskedArray(\n",
    "            cube.data.mask.copy(), mask=match_shape(combined_mask, cube.shape),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    nr_inval_cube.data.mask |= match_shape(np.all(~cube.data.mask, axis=0), cube.shape)\n",
    "\n",
    "    for month_number in tqdm(range(1, 13), desc=\"Months\"):\n",
    "        extracted = iris.Constraint(month_number=month_number).extract(nr_inval_cube)\n",
    "        missing_frac = np.sum(extracted.data, axis=0) / extracted.shape[0]\n",
    "\n",
    "        fig = cube_plotting(\n",
    "            (missing_frac + 1e-5) >= 0.5,\n",
    "            title=f\"{var} month {month_number} missing frac >= 0.5\\n{period_str}\",\n",
    "            colorbar_kwargs={\"label\": \"missing frac >= 0.5\"},\n",
    "            boundaries=boundaries,\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "        )\n",
    "        saver(sub_directory=\"maps\").save_figure(\n",
    "            fig, f\"{var} month {month_number} persistent gaps map\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = figure_saver(sub_directory=\"persistent_gaps\")\n",
    "\n",
    "for var in tqdm(variables, desc=\"Variables\"):\n",
    "    cube = regrid(datasets.select_variables(var, inplace=False).cube.copy())\n",
    "\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    nr_inval_cube = cube.copy(\n",
    "        data=np.ma.MaskedArray(\n",
    "            cube.data.mask.copy(), mask=match_shape(combined_mask, cube.shape),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    nr_inval_cube.data.mask |= match_shape(np.all(~cube.data.mask, axis=0), cube.shape)\n",
    "\n",
    "    for month_number in tqdm(range(1, 13), desc=\"Months\"):\n",
    "        extracted = iris.Constraint(month_number=month_number).extract(nr_inval_cube)\n",
    "        missing_frac = np.sum(extracted.data, axis=0) / extracted.shape[0]\n",
    "\n",
    "        xi, yi = np.where((missing_frac + 1e-5) >= 0.5)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(cube.coord(\"latitude\").points[xi], bins=20)\n",
    "        ax.set_xlim(-90, 90)\n",
    "        ax.set_title(f\"{var} month {month_number} missing >= 50%\")\n",
    "\n",
    "        saver.save_figure(fig, f\"{var} month {month_number} persistent gaps latitudes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Northern Climatological Masks (how many missing samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_str = f\"{timeperiod[0]:%Y-%m} - {timeperiod[1]:%Y-%m}\"\n",
    "\n",
    "saver = figure_saver(sub_directory=\"climatology_masks\")\n",
    "\n",
    "for var in variables:\n",
    "    cube = iris.Constraint(coord_values={\"latitude\": lambda cell: 40 < cell}).extract(\n",
    "        climatologies.select_variables(var, inplace=False).cube.copy()\n",
    "    )\n",
    "\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    # Ignore areas that are always masked, e.g. water.\n",
    "    ignore_mask = np.all(cube.data.mask, axis=0)\n",
    "\n",
    "    cube.data = np.ma.MaskedArray(\n",
    "        cube.data.mask.astype(\"float64\"),\n",
    "        mask=match_shape(ignore_mask, cube.data.shape),\n",
    "    )\n",
    "\n",
    "    fig = cube_plotting(\n",
    "        cube.collapsed(\"month_number\", iris.analysis.MEAN),\n",
    "        title=f\"{var}\\n{period_str}\",\n",
    "        boundaries=np.linspace(0, 1, 6),\n",
    "    )\n",
    "    saver.save_figure(fig, f\"{var} masked samples\")\n",
    "\n",
    "    # Missing fraction by month.\n",
    "    counts = {}\n",
    "    for month_number in range(1, 13):\n",
    "        extracted = iris.Constraint(month_number=month_number).extract(cube)\n",
    "\n",
    "        fig = cube_plotting(\n",
    "            extracted,\n",
    "            title=f\"{var} month {month_number}\\n{period_str}\",\n",
    "            boundaries=np.linspace(0, 1, 6),\n",
    "        )\n",
    "        saver.save_figure(fig, f\"{var} month {month_number} masked samples\")\n",
    "\n",
    "        selected = extracted.data[~extracted.data.mask]\n",
    "        counts[month_number] = np.sum(selected)\n",
    "\n",
    "    with saver(f\"{var} masked months\"):\n",
    "        pd.Series(counts).to_frame(\"masked months\").plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Northern masked climatological timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_str = f\"{timeperiod[0]:%Y-%m} - {timeperiod[1]:%Y-%m}\"\n",
    "\n",
    "saver = figure_saver(sub_directory=\"masked_climatological_timeseries\")\n",
    "\n",
    "for var in variables:\n",
    "    cube = iris.Constraint(coord_values={\"latitude\": lambda cell: 40 < cell}).extract(\n",
    "        climatologies.select_variables(var, inplace=False).cube.copy()\n",
    "    )\n",
    "\n",
    "    if not cube.coords(\"month_number\"):\n",
    "        iris.coord_categorisation.add_month_number(cube, \"time\")\n",
    "\n",
    "    # Ignore areas that are always masked, e.g. water.\n",
    "    ignore_mask = np.all(cube.data.mask, axis=0)\n",
    "\n",
    "    # Ignore areas that are never masked.\n",
    "    ignore_mask |= ~np.any(cube.data.mask, axis=0)\n",
    "\n",
    "    cube.data.mask |= match_shape(ignore_mask, cube.shape)\n",
    "\n",
    "    extracted = cube\n",
    "\n",
    "    cube_plotting(extracted.collapsed(\"month_number\", iris.analysis.MEAN))\n",
    "\n",
    "    class StopPlotting(Exception):\n",
    "        pass\n",
    "\n",
    "    valid_loc = np.sum(np.any(~extracted.data.mask, axis=0))\n",
    "    print(\"number of valid locations:\", valid_loc)\n",
    "\n",
    "    count = 0\n",
    "    thres = 20  # Number of plots to carry out.\n",
    "\n",
    "    # Randomly allow plotting to take place to achieve approx. the intended number.\n",
    "    chance = thres / valid_loc\n",
    "\n",
    "    rng = np.random.RandomState(1)\n",
    "\n",
    "    latitudes = extracted.coord(\"latitude\").points\n",
    "    valid_lats = latitudes[np.any(extracted.data.mask, axis=(0, 2))]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig2, ax2 = plt.subplots()\n",
    "\n",
    "    ax_cb = make_axes_locatable(ax).new_horizontal(size=\"3%\", pad=0.1)\n",
    "    norm = mpl.colors.Normalize(\n",
    "        vmin=np.min(valid_lats), vmax=np.max(valid_lats), clip=True\n",
    "    )\n",
    "    cb = mpl.colorbar.ColorbarBase(\n",
    "        ax_cb, cmap=mpl.cm.viridis, orientation=\"vertical\", norm=norm,\n",
    "    )\n",
    "    fig.add_axes(ax_cb)\n",
    "\n",
    "    ax_cb2 = make_axes_locatable(ax2).new_horizontal(size=\"3%\", pad=0.1)\n",
    "    norm2 = mpl.colors.Normalize(\n",
    "        vmin=np.min(valid_lats), vmax=np.max(valid_lats), clip=True\n",
    "    )\n",
    "    cb2 = mpl.colorbar.ColorbarBase(\n",
    "        ax_cb2, cmap=mpl.cm.viridis, orientation=\"vertical\", norm=norm2,\n",
    "    )\n",
    "    fig2.add_axes(ax_cb2)\n",
    "\n",
    "    try:\n",
    "        for i in tqdm(range(extracted.shape[1]), desc=\"Latitudes\"):\n",
    "            for j in range(extracted.shape[2]):\n",
    "                sel = extracted.data[:, i, j]\n",
    "                if np.all(sel.mask):\n",
    "                    continue\n",
    "\n",
    "                if rng.random() > chance:\n",
    "                    continue\n",
    "\n",
    "                alpha = 0.4\n",
    "\n",
    "                ax.plot(\n",
    "                    range(1, extracted.shape[0] + 1),\n",
    "                    sel,\n",
    "                    c=mpl.cm.viridis(norm(latitudes[i])),\n",
    "                    alpha=alpha,\n",
    "                    zorder=4,\n",
    "                )\n",
    "\n",
    "                ax2.plot(\n",
    "                    range(1, extracted.shape[0] + 1),\n",
    "                    sel / np.max(sel),\n",
    "                    c=mpl.cm.viridis(norm(latitudes[i])),\n",
    "                    alpha=alpha,\n",
    "                    zorder=4,\n",
    "                )\n",
    "\n",
    "                count += 1\n",
    "\n",
    "                # Disable hard exit.\n",
    "                if (count > thres) and False:\n",
    "                    raise StopPlotting()\n",
    "    except StopPlotting:\n",
    "        pass\n",
    "\n",
    "    for _ax in (ax, ax2):\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.vlines(\n",
    "            np.arange(0.5, 62, 12),\n",
    "            ymin=-100,\n",
    "            ymax=100,\n",
    "            colors=\"C3\",\n",
    "            zorder=3,\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.4,\n",
    "        )\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare original to interpolated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_str = f\"{timeperiod[0]:%Y-%m} - {timeperiod[1]:%Y-%m}\"\n",
    "\n",
    "saver = figure_saver(sub_directory=\"interp_comp\")\n",
    "for var in variables:\n",
    "    interp_var = var + f\" {n_months}NN\"\n",
    "    plot_vars = (var, interp_var)\n",
    "    plot_cubes = [\n",
    "        datasets.select_variables(plot_var, inplace=False).cube\n",
    "        for plot_var in plot_vars\n",
    "    ]\n",
    "\n",
    "    for plot_var, plot_cube in zip(plot_vars, plot_cubes):\n",
    "\n",
    "        if not plot_cube.coords(\"month_number\"):\n",
    "            iris.coord_categorisation.add_month_number(plot_cube, \"time\")\n",
    "\n",
    "        fig = cube_plotting(plot_cube, title=f\"{plot_var}\\n{period_str}\")\n",
    "        saver.save_figure(fig, f\"{plot_var} mean\")\n",
    "\n",
    "    replace_cube_coord(plot_cubes[0], plot_cubes[1].coord(\"month_number\"))\n",
    "    replace_cube_coord(plot_cubes[0], plot_cubes[1].coord(\"latitude\"))\n",
    "    replace_cube_coord(plot_cubes[0], plot_cubes[1].coord(\"longitude\"))\n",
    "\n",
    "    mean_1 = np.mean(plot_cubes[1].data, axis=0)\n",
    "    mean_0 = np.mean(plot_cubes[0].data, axis=0)\n",
    "\n",
    "    fig = cube_plotting(\n",
    "        mean_1 - mean_0,\n",
    "        title=f\"{plot_var} <interp> - <normal>\\n{period_str}\",\n",
    "        cmap_midpoint=0,\n",
    "        cmap_symmetric=True,\n",
    "    )\n",
    "    saver.save_figure(fig, f\"{var} interp - normal mean\")\n",
    "\n",
    "    fig = cube_plotting(\n",
    "        100 * (mean_1 - mean_0) / mean_0,\n",
    "        title=f\"{plot_var} (<interp> - <normal>) / <normal> (%)\\n{period_str}\",\n",
    "        cmap_midpoint=0,\n",
    "        cmap_symmetric=True,\n",
    "        colorbar_kwargs={\"label\": \"%\"},\n",
    "        log=True,\n",
    "    )\n",
    "    saver.save_figure(fig, f\"{var} (interp - normal) normalised mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_str = f\"{timeperiod[0]:%Y-%m} - {timeperiod[1]:%Y-%m}\"\n",
    "\n",
    "saver = figure_saver(sub_directory=\"interp_comp_hist\")\n",
    "\n",
    "for var in variables:\n",
    "    interp_var = var + f\" {n_months}NN\"\n",
    "    plot_vars = (var, interp_var)\n",
    "    plot_cubes = [\n",
    "        datasets.select_variables(plot_var, inplace=False).cube\n",
    "        for plot_var in plot_vars\n",
    "    ]\n",
    "\n",
    "    for plot_var, plot_cube in zip(plot_vars, plot_cubes):\n",
    "\n",
    "        if not plot_cube.coords(\"month_number\"):\n",
    "            iris.coord_categorisation.add_month_number(plot_cube, \"time\")\n",
    "\n",
    "    replace_cube_coord(plot_cubes[0], plot_cubes[1].coord(\"month_number\"))\n",
    "    replace_cube_coord(plot_cubes[0], plot_cubes[1].coord(\"latitude\"))\n",
    "    replace_cube_coord(plot_cubes[0], plot_cubes[1].coord(\"longitude\"))\n",
    "\n",
    "    mean_1 = np.mean(plot_cubes[1].data, axis=0)\n",
    "    mean_0 = np.mean(plot_cubes[0].data, axis=0)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist((mean_1 - mean_0).flatten(), bins=200)\n",
    "    ax.set_title(f\"{plot_var} <interp> - <normal>\\n{period_str}\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(f\"{plot_var}\")\n",
    "    saver.save_figure(fig, f\"{var} interp - normal hist\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist((100 * (mean_1 - mean_0) / mean_0).flatten(), bins=200)\n",
    "    ax.set_title(f\"{plot_var} (<interp> - <normal>) / <normal> (%)\\n{period_str}\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"%\")\n",
    "    saver.save_figure(fig, f\"{var} (interp - normal) normalised hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_str = f\"{timeperiod[0]:%Y-%m} - {timeperiod[1]:%Y-%m}\"\n",
    "\n",
    "saver = figure_saver(sub_directory=\"interp_comp_timeseries\")\n",
    "\n",
    "for var in variables:\n",
    "    interp_var = var + f\" {n_months}NN\"\n",
    "    plot_vars = (var, interp_var)\n",
    "    plot_cubes = [\n",
    "        datasets.select_variables(plot_var, inplace=False).cube\n",
    "        for plot_var in plot_vars\n",
    "    ]\n",
    "\n",
    "    for plot_var, plot_cube in zip(plot_vars, plot_cubes):\n",
    "        if not plot_cube.coords(\"month_number\"):\n",
    "            iris.coord_categorisation.add_month_number(plot_cube, \"time\")\n",
    "\n",
    "    for coord in (\"time\", \"latitude\", \"longitude\"):\n",
    "        assert np.all(\n",
    "            plot_cubes[0].coord(coord).points == plot_cubes[1].coord(coord).points\n",
    "        )\n",
    "\n",
    "    replace_cube_coord(plot_cubes[0], plot_cubes[1].coord(\"month_number\"))\n",
    "    replace_cube_coord(plot_cubes[0], plot_cubes[1].coord(\"latitude\"))\n",
    "    replace_cube_coord(plot_cubes[0], plot_cubes[1].coord(\"longitude\"))\n",
    "\n",
    "    mean_1 = np.mean(plot_cubes[1].data, axis=0)\n",
    "    mean_0 = np.mean(plot_cubes[0].data, axis=0)\n",
    "\n",
    "    normal_data = plot_cubes[0].data\n",
    "    interp_data = plot_cubes[1].data\n",
    "\n",
    "    mean_diff_data = (mean_1 - mean_0) / mean_0\n",
    "\n",
    "    unmasked = get_unmasked(mean_diff_data)\n",
    "    sort_indices = np.argsort(np.abs(unmasked))\n",
    "    for diff_i in sort_indices[-20:]:\n",
    "        diff = unmasked[diff_i]\n",
    "        indices = np.where(mean_diff_data == diff)\n",
    "\n",
    "        lat = plot_cubes[0].coord(\"latitude\").points[indices[0][0]]\n",
    "        lon = plot_cubes[0].coord(\"longitude\").points[indices[1][0]]\n",
    "\n",
    "        lat_str = f\"{abs(lat):0.1f}\" + (\"°N\" if lat >= 0 else \"°S\")\n",
    "        lon_str = f\"{abs(lon):0.1f}\" + (\"°E\" if lon >= 0 else \"°W\")\n",
    "        loc_str = f\"{lat_str}, {lon_str}\"\n",
    "\n",
    "        normal_data_sel = normal_data[:, indices[0][0], indices[1][0]]\n",
    "        interp_data_sel = interp_data[:, indices[0][0], indices[1][0]]\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(f\"{plot_var}, {diff:0.1f}\\n{period_str}, {loc_str}\")\n",
    "        ax.plot(normal_data_sel, marker=\"o\", label=\"Original\")\n",
    "        ax.plot(interp_data_sel, marker=\"x\", linestyle=\"--\", label=\"Interpolated\")\n",
    "        ax.legend(loc=\"best\")\n",
    "        saver.save_figure(fig, f\"{var}_{lat:0.1f}_{lon:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_plotting(mean_diff_data.mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
