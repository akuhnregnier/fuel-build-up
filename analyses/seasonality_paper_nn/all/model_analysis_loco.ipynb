{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specific import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve previous results from the 'model' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_split_cache.load()\n",
    "rf = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_path():\n",
    "    import sys\n",
    "\n",
    "    return sys.path\n",
    "\n",
    "\n",
    "client.submit(print_path).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.scheduler_info()['workers']['tcp://10.149.10.103:40991']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p2():\n",
    "    import wildfires\n",
    "\n",
    "    return str(wildfires)\n",
    "\n",
    "\n",
    "for worker in client.scheduler_info()[\"workers\"]:\n",
    "    # print(worker)\n",
    "    # print(client.submit(print_path, pure=False, workers={worker}).result())\n",
    "    try:\n",
    "        print(client.submit(p2, pure=False, workers={worker}).result())\n",
    "    except:\n",
    "        print(\"Failed:\", worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(n_workers=1, threads_per_worker=8, resources={'threads': 8})\n",
    "client = get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask LOCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loco_cache = SimpleCache(\"loco_results\", cache_dir=CACHE_DIR)\n",
    "\n",
    "leave_out = [\"\"]\n",
    "leave_out.extend(X_train.columns)\n",
    "\n",
    "# XXX:\n",
    "# loco_cache.clear()\n",
    "\n",
    "\n",
    "@loco_cache\n",
    "def get_loco_scores():\n",
    "    return dict(\n",
    "        dask_fit_loco(\n",
    "            rf, X_train, y_train, client, leave_out, local_n_jobs=31, verbose=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "scores = get_loco_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-python3-ffmpeg"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
