{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specific import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    endog_data,\n",
    "    exog_data,\n",
    "    master_mask,\n",
    "    filled_datasets,\n",
    "    masked_datasets,\n",
    "    land_mask,\n",
    ") = get_offset_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve previous results from the 'model' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_split_cache.load()\n",
    "results, rf = cross_val_cache.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values - see PBS (array) job folder 'shap'!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the SHAP values (keeping track of missing chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 995  # Maximum job array index (inclusive).\n",
    "job_samples = 2000  # Samples per job.\n",
    "total_samples = (max_index + 1) * job_samples  # Sanity check.\n",
    "\n",
    "# Load the individual data chunks.\n",
    "shap_chunks = []\n",
    "missing = []\n",
    "for index in tqdm(range(max_index + 1), desc=\"Loading chunks\"):\n",
    "    try:\n",
    "        shap_chunks.append(\n",
    "            SimpleCache(\n",
    "                f\"tree_path_dependent_shap_{index}_{job_samples}\",\n",
    "                cache_dir=os.path.join(CACHE_DIR, \"shap\"),\n",
    "                verbose=0,\n",
    "            ).load()\n",
    "        )\n",
    "    except NoCachedDataError:\n",
    "        missing.append(index)\n",
    "\n",
    "if missing:\n",
    "    print(\"missing:\", missing)\n",
    "    print(\"nr missing:\", len(missing))\n",
    "\n",
    "shap_values = np.vstack(shap_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BA in the train and test sets\n",
    "\n",
    "Valid elements are situated where master_mask is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indices = np.where(~master_mask.ravel())[0]\n",
    "\n",
    "valid_train_indices, valid_test_indices = train_test_split(\n",
    "    valid_indices, random_state=1, shuffle=True, test_size=0.3\n",
    ")\n",
    "\n",
    "masked_train_data = np.ma.MaskedArray(\n",
    "    np.zeros_like(master_mask, dtype=np.float64), mask=np.ones_like(master_mask)\n",
    ")\n",
    "masked_train_data.ravel()[valid_train_indices] = y_train.values\n",
    "\n",
    "masked_test_data = np.ma.MaskedArray(\n",
    "    np.zeros_like(master_mask, dtype=np.float64), mask=np.ones_like(master_mask)\n",
    ")\n",
    "masked_test_data.ravel()[valid_test_indices] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with map_figure_saver(\"train_test_set_overall_ba_comp\"):\n",
    "    fig, axes = plt.subplots(\n",
    "        3,\n",
    "        1,\n",
    "        constrained_layout=True,\n",
    "        figsize=(5.1, 8.4),\n",
    "        subplot_kw={\"projection\": ccrs.Robinson()},\n",
    "    )\n",
    "    shared_kwargs = {\n",
    "        \"boundaries\": [0, 4e-6, 1e-5, 1e-4, 1e-3, 1e-2, 8e-2],\n",
    "        \"extend\": \"max\",\n",
    "        \"cmap\": \"inferno\",\n",
    "        \"colorbar_kwargs\": {\"format\": \"%0.1e\", \"label\": \"Fractional BA\"},\n",
    "        \"coastline_kwargs\": {\"linewidth\": 0.3},\n",
    "        \"title\": \"\",\n",
    "    }\n",
    "    axes[0].set_title(\"Mean Overall GFED4 BA\")\n",
    "    cube_plotting(\n",
    "        get_masked_array(endog_data.values, master_mask),\n",
    "        ax=axes[0],\n",
    "        fig=fig,\n",
    "        **shared_kwargs\n",
    "    )\n",
    "    axes[1].set_title(\"Mean Train Set GFED4 BA\")\n",
    "    cube_plotting(masked_train_data, ax=axes[1], fig=fig, **shared_kwargs)\n",
    "    axes[2].set_title(\"Mean Test Set GFED4 BA\")\n",
    "    cube_plotting(masked_test_data, ax=axes[2], fig=fig, **shared_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.abs(shap_values[:, 0]), bins=5000)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate 2D masked array SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_shap_arrs = []\n",
    "vmins = []\n",
    "vmaxs = []\n",
    "\n",
    "for i, feature in enumerate(tqdm(X_train.columns, desc=\"Computing SHAP values\")):\n",
    "    masked_shap_comp = np.ma.MaskedArray(\n",
    "        np.zeros_like(master_mask, dtype=np.float64), mask=np.ones_like(master_mask)\n",
    "    )\n",
    "    masked_shap_comp.ravel()[valid_train_indices[: shap_values.shape[0]]] = shap_values[\n",
    "        :, i\n",
    "    ]\n",
    "    avg_shap_comp = np.ma.mean(masked_shap_comp, axis=0)\n",
    "    masked_shap_arrs.append(avg_shap_comp)\n",
    "    vmins.append(np.min(avg_shap_comp))\n",
    "    vmaxs.append(np.max(avg_shap_comp))\n",
    "\n",
    "vmin = min(vmins)\n",
    "vmax = max(vmaxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting maps of SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(tqdm(X_train.columns, desc=\"Mapping SHAP values\")):\n",
    "    fig = cube_plotting(\n",
    "        masked_shap_arrs[i],\n",
    "        fig=plt.figure(figsize=(5.1, 2.8)),\n",
    "        title=f\"Mean SHAP value for '{shorten_features(feature)}'\",\n",
    "        cmap=\"Spectral_r\",\n",
    "        nbins=7,\n",
    "        cmap_midpoint=0,\n",
    "        cmap_symmetric=True,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        log=True,\n",
    "        log_auto_bins=False,\n",
    "        min_edge=1e-3,\n",
    "        extend=\"neither\",\n",
    "        colorbar_kwargs={\n",
    "            \"format\": \"%0.1e\",\n",
    "            \"label\": f\"SHAP ('{shorten_features(feature)}')\",\n",
    "        },\n",
    "        coastline_kwargs={\"linewidth\": 0.3},\n",
    "    )\n",
    "    map_figure_saver.save_figure(\n",
    "        fig, f\"shap_value_map_{feature}\", sub_directory=\"shap_map\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find common mask for a range of 2D SHAP arrays to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_month = 9\n",
    "\n",
    "# Mark areas where at least this fraction of |SHAP| has been plotted previously.\n",
    "thres = 0.7\n",
    "\n",
    "\n",
    "def param_iter():\n",
    "    for exclude_inst in tqdm([False, True], desc=\"Exclude inst.\"):\n",
    "        for feature_name in tqdm(\n",
    "            [\"VOD Ku-band\", \"SIF\", \"FAPAR\", \"LAI\", \"Dry Day Period\"], desc=\"Feature\"\n",
    "        ):\n",
    "            yield exclude_inst, feature_name\n",
    "\n",
    "\n",
    "for exclude_inst, feature_name in param_iter():\n",
    "    if exclude_inst:\n",
    "        sub_directory = \"rank_shap_map_no_inst\"\n",
    "    else:\n",
    "        sub_directory = \"rank_shap_map\"\n",
    "\n",
    "    filtered = np.array(filter_by_month(X_train.columns, feature_name, max_month))\n",
    "    lags = np.array(\n",
    "        [get_lag(feature, target_feature=feature_name) for feature in filtered]\n",
    "    )\n",
    "\n",
    "    # Ensure lags are sorted consistently.\n",
    "    lag_sort_inds = np.argsort(lags)\n",
    "    filtered = tuple(filtered[lag_sort_inds])\n",
    "    lags = tuple(lags[lag_sort_inds])\n",
    "\n",
    "    if exclude_inst:\n",
    "        if 0 in lags:\n",
    "            assert lags[0] == 0\n",
    "            lags = lags[1:]\n",
    "            filtered = filtered[1:]\n",
    "\n",
    "    n_features = len(filtered)\n",
    "\n",
    "    # There is no point plotting this map for a single feature or less since we are\n",
    "    # interested in a comparison between different feature ranks.\n",
    "    if n_features <= 1:\n",
    "        continue\n",
    "\n",
    "    selected_data = np.empty(n_features, dtype=object)\n",
    "    for i, col in enumerate(X_train.columns):\n",
    "        if col in filtered:\n",
    "            selected_data[lags.index(get_lag(col))] = masked_shap_arrs[i].copy()\n",
    "\n",
    "    shared_mask = reduce(np.logical_or, (data.mask for data in selected_data))\n",
    "    for data in selected_data:\n",
    "        data.mask = shared_mask\n",
    "\n",
    "    stacked_abs = np.abs(np.vstack([data.data[np.newaxis] for data in selected_data]))\n",
    "    # Indices in descending order.\n",
    "    sort_indices = np.argsort(stacked_abs, axis=0)[::-1]\n",
    "\n",
    "    # Maintain the same colors even if fewer colors are used.\n",
    "    colors = [lag_color_dict[lag] for lag in lags]\n",
    "\n",
    "    cmap, norm = from_levels_and_colors(\n",
    "        levels=np.arange(n_features + 1), colors=colors, extend=\"neither\",\n",
    "    )\n",
    "\n",
    "    short_feature = shorten_features(feature_name)\n",
    "\n",
    "    sum_shap = np.ma.MaskedArray(np.sum(stacked_abs, axis=0), mask=shared_mask)\n",
    "    already_plotted = np.zeros_like(sum_shap)\n",
    "\n",
    "    for i, rank in zip(\n",
    "        tqdm(range(n_features), desc=\"Plotting\", leave=False),\n",
    "        [\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\"],\n",
    "    ):\n",
    "        cube = dummy_lat_lon_cube(np.ma.MaskedArray(sort_indices[i], mask=shared_mask))\n",
    "\n",
    "        fig, ax = plt.subplots(\n",
    "            figsize=(5.1, 2.6), subplot_kw={\"projection\": ccrs.Robinson()}\n",
    "        )\n",
    "\n",
    "        style = 2\n",
    "\n",
    "        if style == 1:\n",
    "            # Stippling for significant areas.\n",
    "            mpl.rc(\"hatch\", linewidth=0.2)\n",
    "            hatches = [\".\" * 6, None]\n",
    "        else:\n",
    "            # Hatching for insignificant areas.\n",
    "            mpl.rc(\"hatch\", linewidth=0.1)\n",
    "            hatches = [\"/\" * 14, None]\n",
    "\n",
    "        if np.any(already_plotted >= thres):\n",
    "            ax.contourf(\n",
    "                cube.coord(\"longitude\").points,\n",
    "                cube.coord(\"latitude\").points,\n",
    "                already_plotted,\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                colors=\"none\",\n",
    "                zorder=4,\n",
    "                levels=[thres, 1],\n",
    "                hatches=hatches,\n",
    "            )\n",
    "\n",
    "        fig, cbar = cube_plotting(\n",
    "            cube,\n",
    "            title=f\"{rank} |SHAP {short_feature} Lag| - thres: {thres * 100:0.0f}%\",\n",
    "            fig=fig,\n",
    "            ax=ax,\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "            return_cbar=True,\n",
    "            colorbar_kwargs={\"label\": short_feature},\n",
    "            coastline_kwargs={\"linewidth\": 0.3},\n",
    "        )\n",
    "\n",
    "        # Label the colorbar using the feature names.\n",
    "        cbar.set_ticks(np.arange(n_features) + 0.5)\n",
    "\n",
    "        labels = []\n",
    "        for lag in lags:\n",
    "            if lag:\n",
    "                labels.append(f\"{lag} M\")\n",
    "            else:\n",
    "                labels.append(\"Inst.\")\n",
    "        cbar.set_ticklabels(labels)\n",
    "\n",
    "        data = np.take_along_axis(stacked_abs, sort_indices[i : i + 1], axis=0)[0]\n",
    "        already_plotted += data / sum_shap\n",
    "\n",
    "        map_figure_saver.save_figure(\n",
    "            fig, f\"{rank}_{short_feature}\", sub_directory=sub_directory\n",
    "        )\n",
    "        plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires]",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
